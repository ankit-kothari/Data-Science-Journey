{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d11dd99ec99e462682eb1921d1a851f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f522e91d667a4f1b9ed5c46d4ad5950b",
              "IPY_MODEL_73e836c68fe34107806fde2106b4cfb1",
              "IPY_MODEL_a1f03f5b017c4ff184a567cd18aba351"
            ],
            "layout": "IPY_MODEL_5b99f1a25f9444a08ed1a9278669f57c"
          }
        },
        "f522e91d667a4f1b9ed5c46d4ad5950b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_286eb08d53e94ceeb79b4f596b8dd7fa",
            "placeholder": "​",
            "style": "IPY_MODEL_5566f5e6fba74cd2bb2ad0c05262aec8",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "73e836c68fe34107806fde2106b4cfb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b72f4d39c841b093b73fcf251669a1",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48bcc79b09d24165bbba55040b3140cd",
            "value": 665
          }
        },
        "a1f03f5b017c4ff184a567cd18aba351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb0fe67ad45e440e85f9b4bdddea250a",
            "placeholder": "​",
            "style": "IPY_MODEL_9b90ad672ff4471890f3a5f895cdf3b5",
            "value": " 665/665 [00:00&lt;00:00, 20.1kB/s]"
          }
        },
        "5b99f1a25f9444a08ed1a9278669f57c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286eb08d53e94ceeb79b4f596b8dd7fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5566f5e6fba74cd2bb2ad0c05262aec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3b72f4d39c841b093b73fcf251669a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48bcc79b09d24165bbba55040b3140cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb0fe67ad45e440e85f9b4bdddea250a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b90ad672ff4471890f3a5f895cdf3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "527196177f4d47a08b2774c8aa51919f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_594359d18c1f40f9aab37f81b453caeb",
              "IPY_MODEL_4b3c5201c9e949a9b616cd7d16e74da5",
              "IPY_MODEL_f022d475e7c44fb89b15e8ca12dbf949"
            ],
            "layout": "IPY_MODEL_d5f775b213f743eeb6d8549135187ab7"
          }
        },
        "594359d18c1f40f9aab37f81b453caeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3547243030ec4ed091c073cfb0b65f30",
            "placeholder": "​",
            "style": "IPY_MODEL_6bfe78cbf2fa44929fa5e9c898be7302",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "4b3c5201c9e949a9b616cd7d16e74da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d72456493214258b2244620860d8eac",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e3beaebf32d4454b6457ff5ad771e0f",
            "value": 548105171
          }
        },
        "f022d475e7c44fb89b15e8ca12dbf949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82006bc922ae4aa693fbd156f540b0e2",
            "placeholder": "​",
            "style": "IPY_MODEL_449dd178b6c84dfd9abaf63154ebdfe0",
            "value": " 548M/548M [00:04&lt;00:00, 123MB/s]"
          }
        },
        "d5f775b213f743eeb6d8549135187ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3547243030ec4ed091c073cfb0b65f30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bfe78cbf2fa44929fa5e9c898be7302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d72456493214258b2244620860d8eac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e3beaebf32d4454b6457ff5ad771e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82006bc922ae4aa693fbd156f540b0e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449dd178b6c84dfd9abaf63154ebdfe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32c7ea936a964d5cbd67b5e2e875721d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc69ca4cfc514b3d88e303a6c9840fa5",
              "IPY_MODEL_da1a7a261076482887ff1ec79dbf8ad1",
              "IPY_MODEL_737694c3427b4ef08fbe1bf22dd821e6"
            ],
            "layout": "IPY_MODEL_1707857a02b04613a49662d6296932b4"
          }
        },
        "dc69ca4cfc514b3d88e303a6c9840fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c1ba52eb3b443439d11d1099241a92c",
            "placeholder": "​",
            "style": "IPY_MODEL_ad8ac6e44b1d42849e6b0ef223c58c02",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "da1a7a261076482887ff1ec79dbf8ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6ec838dd9de40d6bb95ed65ccfb216b",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f13e899f4cd648f394f389cce730cb0a",
            "value": 124
          }
        },
        "737694c3427b4ef08fbe1bf22dd821e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a3ccaa9181442fabf749a312ec2e12a",
            "placeholder": "​",
            "style": "IPY_MODEL_cffa18ffff4946bc89adc67f495e4139",
            "value": " 124/124 [00:00&lt;00:00, 4.94kB/s]"
          }
        },
        "1707857a02b04613a49662d6296932b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c1ba52eb3b443439d11d1099241a92c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8ac6e44b1d42849e6b0ef223c58c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6ec838dd9de40d6bb95ed65ccfb216b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13e899f4cd648f394f389cce730cb0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a3ccaa9181442fabf749a312ec2e12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cffa18ffff4946bc89adc67f495e4139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e045a46c076f46f19c9b5089f751e53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ee36d577962455a87a4d8f305f3338d",
              "IPY_MODEL_6c01dd9175574203b886f1e5749b7cd3",
              "IPY_MODEL_225fb4bbd67841c597e3647cb6af9d28"
            ],
            "layout": "IPY_MODEL_b9471f3196934ffeb51d1c0e6c37211f"
          }
        },
        "4ee36d577962455a87a4d8f305f3338d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ccbbe836dd425cafb8e9b8667d23f2",
            "placeholder": "​",
            "style": "IPY_MODEL_b47b9acb39fb4c86bcf72ca3a5999fb4",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "6c01dd9175574203b886f1e5749b7cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_014a5c20159d46b1a411985d880e17f3",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08e63fe60a5c4c74a84feeef926735b6",
            "value": 28
          }
        },
        "225fb4bbd67841c597e3647cb6af9d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d0bd924024445e48d23736159aaefba",
            "placeholder": "​",
            "style": "IPY_MODEL_8304e9a8f3214cf196fda75b9c7d2ba3",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.64kB/s]"
          }
        },
        "b9471f3196934ffeb51d1c0e6c37211f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ccbbe836dd425cafb8e9b8667d23f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b47b9acb39fb4c86bcf72ca3a5999fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "014a5c20159d46b1a411985d880e17f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e63fe60a5c4c74a84feeef926735b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d0bd924024445e48d23736159aaefba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8304e9a8f3214cf196fda75b9c7d2ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5af5635bf32445cba4cc7c40baa9aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82db5b111c5941239986db846a1b72ba",
              "IPY_MODEL_ab590417cab84be2bf2250272ba1bd25",
              "IPY_MODEL_9d1f08ff21ca45818553936ad837b853"
            ],
            "layout": "IPY_MODEL_e753920de7774bb597da88426d14700c"
          }
        },
        "82db5b111c5941239986db846a1b72ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04bea70e4709434a947593603bf89dfa",
            "placeholder": "​",
            "style": "IPY_MODEL_0713f077f03f49ac8b6d7c018f9c1826",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ab590417cab84be2bf2250272ba1bd25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a1edf2304b4084bdb5feaf04dfb6d0",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a01129a4638744e5850a492f2c2e42fb",
            "value": 570
          }
        },
        "9d1f08ff21ca45818553936ad837b853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07a635a17ab24716a7701257513c794d",
            "placeholder": "​",
            "style": "IPY_MODEL_6c901c3694454d8fbfafdd83fadad730",
            "value": " 570/570 [00:00&lt;00:00, 38.5kB/s]"
          }
        },
        "e753920de7774bb597da88426d14700c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04bea70e4709434a947593603bf89dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0713f077f03f49ac8b6d7c018f9c1826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97a1edf2304b4084bdb5feaf04dfb6d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01129a4638744e5850a492f2c2e42fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07a635a17ab24716a7701257513c794d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c901c3694454d8fbfafdd83fadad730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afd8b0c38dcf421db8466109a330b3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d751cfb6ebc49019902fa9e4ba30aff",
              "IPY_MODEL_28a92d6d2cf84da789bb2c70f513b7c2",
              "IPY_MODEL_f1bb0fed260c4924a9ee310763b05fde"
            ],
            "layout": "IPY_MODEL_3629d73293934ff899f366e2091f38a7"
          }
        },
        "0d751cfb6ebc49019902fa9e4ba30aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b43a40ca9b304ed89ad85a2bc2b54d33",
            "placeholder": "​",
            "style": "IPY_MODEL_9858098e9aaa4c879af6d65c73caa6a4",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "28a92d6d2cf84da789bb2c70f513b7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f943b0ef7e449aa6f0748097c9c29b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d2f1c08c9fd4fb6af9bd4b50c30c649",
            "value": 231508
          }
        },
        "f1bb0fed260c4924a9ee310763b05fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4429aa9fdb984c61be820f113a404089",
            "placeholder": "​",
            "style": "IPY_MODEL_2cb9959530994295b25f35bb0a185877",
            "value": " 232k/232k [00:00&lt;00:00, 3.38MB/s]"
          }
        },
        "3629d73293934ff899f366e2091f38a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b43a40ca9b304ed89ad85a2bc2b54d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9858098e9aaa4c879af6d65c73caa6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5f943b0ef7e449aa6f0748097c9c29b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2f1c08c9fd4fb6af9bd4b50c30c649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4429aa9fdb984c61be820f113a404089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cb9959530994295b25f35bb0a185877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ef725b356a948718f076bb64b25ce52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_241da360870f4a3199a559801d78ac7f",
              "IPY_MODEL_ac06eddcd78d46daba8cdd9bd3250605",
              "IPY_MODEL_df786e7cd80a46e1bd66762d3988b5bc"
            ],
            "layout": "IPY_MODEL_af6327506f4d4e6e8f6afb6ae2abd419"
          }
        },
        "241da360870f4a3199a559801d78ac7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab9ffa99f5da47edbc239f3229f3b251",
            "placeholder": "​",
            "style": "IPY_MODEL_c086f4da226f43628d88e4cbe02b8aa7",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "ac06eddcd78d46daba8cdd9bd3250605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e618f3231e9240619a72a652179a1c93",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f0e5dd0b7b145aba5dba8932b40e719",
            "value": 466062
          }
        },
        "df786e7cd80a46e1bd66762d3988b5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_057ca7b6b60e4081aa86f00cf5101627",
            "placeholder": "​",
            "style": "IPY_MODEL_0d12c31cef644922a25e427621a7a82d",
            "value": " 466k/466k [00:00&lt;00:00, 8.30MB/s]"
          }
        },
        "af6327506f4d4e6e8f6afb6ae2abd419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab9ffa99f5da47edbc239f3229f3b251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c086f4da226f43628d88e4cbe02b8aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e618f3231e9240619a72a652179a1c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f0e5dd0b7b145aba5dba8932b40e719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "057ca7b6b60e4081aa86f00cf5101627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d12c31cef644922a25e427621a7a82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Week 2 - Transformers 🤖: MLPs in Disguise** (~2 hrs total)"
      ],
      "metadata": {
        "id": "04PZJ_WLbmZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0 - Setup (~1 min)\n",
        "Before you begin, please clone this notebook!\n",
        "\n",
        "**File > Save a copy in Drive**"
      ],
      "metadata": {
        "id": "-Vsd23TK6NCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import exception\n",
        "#@title Step 1: Mount drive\n",
        "#@markdown Run this cell. If prompted, press \"Connect to Google Drive\" and select your Google account.\n",
        "#@markdown Then, under the folder icon 📁 on the left panel, you should see the folder **drive** appear.\n",
        "from google.colab import drive\n",
        "from IPython.display import display, Markdown, HTML\n",
        "import os, sys\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "try:\n",
        "  drive.mount('/content/drive', force_remount=False)\n",
        "  sys.path.append('/content/drive/MyDrive/DLE-Jun23/Projects')\n",
        "  os.chdir('/content/drive/MyDrive/Colab Notebooks/')\n",
        "  display(\"⭐ Mounted successfully!\")\n",
        "except:\n",
        "  display(HTML('<span style=\"color:red\">An error occurred. Try again!</span>'))\n"
      ],
      "metadata": {
        "id": "oxAUjGRSbuTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "271de73f-8afc-426d-89d0-48f5ac299d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'⭐ Mounted successfully!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ankit-kothari/minGPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu61TsMcrEhx",
        "outputId": "3889dfaf-b59c-465b-acf0-793a62f44ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'minGPT' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#@title Step 2: Import packages\n",
        "!pip install gradio tiktoken transformers bertviz sentence_transformers\n",
        "!git clone https://github.com/ankit-kothari/minGPT\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/minGPT')\n",
        "import gradio as gr\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from dle_utils.dle_utils import *\n",
        "\n",
        "import os\n",
        "import tiktoken\n",
        "from contextlib import nullcontext\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "import bertviz\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "id": "EZ4gFztrcAHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: Accessing minGPT\n",
        "\n",
        "In this assignment, you'll be modifying files in a GitHub repo you have just cloned. This is located in\n",
        "\n",
        "`/content/drive/MyDrive/Colab Notebooks/minGPT`\n",
        "\n",
        "After you navigate to this folder, you can open files directly and modify them within Colab.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1v88T2um69mf4W4Jvzt2f-Se8-YlDDZmz\" width=300/>"
      ],
      "metadata": {
        "id": "bdUbql4zc-wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 0: Enter your name to begin.\n",
        "#@markdown Enter your name as it appears in Slack and run this cell! This is optional -- you can also leave this blank.\n",
        "Name = ' Ankit' #@param {type:\"string\"}\n",
        "filepath = '/content/drive/MyDrive/Colab Notebooks/dle_info.txt'\n",
        "if os.path.exists(filepath):\n",
        "  print(\"Success!\")\n",
        "else:\n",
        "  if len(Name) == 0:\n",
        "    print(\"Please set your name!\")\n",
        "  else:\n",
        "    try:\n",
        "      with open(filepath, 'w') as fp:\n",
        "        fp.write(Name)\n",
        "        dle_username = Name\n",
        "      print(\"Success!\")\n",
        "    except:\n",
        "      print(\"Something went wrong...\")\n"
      ],
      "metadata": {
        "id": "Y03RSXQvcUjf",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1014875c-35be-4b17-f52f-470b2945ed71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: The Life of a Prompt (~10 min)\n",
        "\n",
        "<img src=\"https://seeklogo.com/images/C/chatgpt-logo-02AFA704B5-seeklogo.com.png\" width='200px' height='200px'>\n",
        "\n",
        "What happens when we type a prompt into ChatGPT? How does it know what to say? (How can we know it's not just a person pretending to be an AI on the other end? 😏).\n",
        "\n",
        "ChatGPT uses **GPT-3** as the backbone model for all of its responses. By backbone model, we mean that this is the model that interprets and aims to \"understand\" the prompt. There are other bells and whistles that are needed to make the experience smoother, but GPT-3 is the brains 🧠 behind everything.\n",
        "\n",
        "In this section will cover the basics of GPT (Generative Pre-trained Transformer). GPT was developed by OpenAI, and serves as the backbone of their flagship product, Chat-GPT.\n",
        "\n",
        "We will be working with a simplified version of GPT called minGPT (written by *Andrej Karpathy*) to be a more human-understandable implementation. Also, we'll be using GPT-2, which is a smaller, earlier version of GPT-3. Though different, there are actually very few conceptual differences between GPT-2 and GPT-3!\n",
        "\n",
        "**TODO**:\n",
        "\n",
        "Open up ```minGPT/mingpt/model.py``` in the folder tab on the left side of this notebook by double clicking its name. It should then appear on the right hand side of this notebook. The model we will be using is defined under ```class GPT(nn.Module)```.\n",
        "\n",
        "We'll dig into the model in a second. First, let's just run some examples through it to get a feel.\n",
        "\n",
        "**Run the cell below.** This cell loads the GPT-2 model and creates a function, `generate_text()`, that generates text using GPT-2 given a prompt."
      ],
      "metadata": {
        "id": "a_fF1tq1n2RC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from minGPT import mingpt\n",
        "from mingpt.model import GPT\n",
        "from mingpt.bpe import BPETokenizer\n",
        "\n",
        "model = GPT.from_pretrained('gpt2')\n",
        "tokenizer = BPETokenizer()\n",
        "\n",
        "def generate_text(prompt, model=model, num_samples=3, num_tokens_per_response=50):\n",
        "  x = tokenizer(prompt).expand(num_samples, -1)\n",
        "  print(x)\n",
        "  response = model.generate(x, max_new_tokens=num_tokens_per_response, do_sample=True, top_k=5)\n",
        "  print(prompt)\n",
        "  print('-'*80)\n",
        "  for i in range(num_samples):\n",
        "    print(f'Response {i+1}: {tokenizer.decode(response[i].cpu().squeeze())[len(prompt):]}')\n",
        "    print('-'*80)"
      ],
      "metadata": {
        "id": "xw8cepvdoLqh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "d11dd99ec99e462682eb1921d1a851f5",
            "f522e91d667a4f1b9ed5c46d4ad5950b",
            "73e836c68fe34107806fde2106b4cfb1",
            "a1f03f5b017c4ff184a567cd18aba351",
            "5b99f1a25f9444a08ed1a9278669f57c",
            "286eb08d53e94ceeb79b4f596b8dd7fa",
            "5566f5e6fba74cd2bb2ad0c05262aec8",
            "f3b72f4d39c841b093b73fcf251669a1",
            "48bcc79b09d24165bbba55040b3140cd",
            "cb0fe67ad45e440e85f9b4bdddea250a",
            "9b90ad672ff4471890f3a5f895cdf3b5",
            "527196177f4d47a08b2774c8aa51919f",
            "594359d18c1f40f9aab37f81b453caeb",
            "4b3c5201c9e949a9b616cd7d16e74da5",
            "f022d475e7c44fb89b15e8ca12dbf949",
            "d5f775b213f743eeb6d8549135187ab7",
            "3547243030ec4ed091c073cfb0b65f30",
            "6bfe78cbf2fa44929fa5e9c898be7302",
            "4d72456493214258b2244620860d8eac",
            "8e3beaebf32d4454b6457ff5ad771e0f",
            "82006bc922ae4aa693fbd156f540b0e2",
            "449dd178b6c84dfd9abaf63154ebdfe0",
            "32c7ea936a964d5cbd67b5e2e875721d",
            "dc69ca4cfc514b3d88e303a6c9840fa5",
            "da1a7a261076482887ff1ec79dbf8ad1",
            "737694c3427b4ef08fbe1bf22dd821e6",
            "1707857a02b04613a49662d6296932b4",
            "6c1ba52eb3b443439d11d1099241a92c",
            "ad8ac6e44b1d42849e6b0ef223c58c02",
            "c6ec838dd9de40d6bb95ed65ccfb216b",
            "f13e899f4cd648f394f389cce730cb0a",
            "6a3ccaa9181442fabf749a312ec2e12a",
            "cffa18ffff4946bc89adc67f495e4139"
          ]
        },
        "outputId": "b4974a7d-9544-4bf4-a30f-6aa88f961992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 124.44M\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d11dd99ec99e462682eb1921d1a851f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "527196177f4d47a08b2774c8aa51919f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32c7ea936a964d5cbd67b5e2e875721d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading https://openaipublic.blob.core.windows.net/gpt-2/models/124M/encoder.json to /root/.cache/mingpt/encoder.json\n",
            "downloading https://openaipublic.blob.core.windows.net/gpt-2/models/124M/vocab.bpe to /root/.cache/mingpt/vocab.bpe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Try a prompt\n",
        "#@markdown In this cell, type in a prompt, starting with the default.\n",
        "Prompt = 'The Indian Prime Minister Mr. Modi ' #@param {type:\"string\"}\n",
        "\n",
        "generate_text(Prompt)"
      ],
      "metadata": {
        "id": "Zgb2Bu8sAn7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49561ef-dc66-4b0e-99d8-20ba12eab987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  464,  3942,  5537,  4139,  1770,    13, 14637,   220],\n",
            "        [  464,  3942,  5537,  4139,  1770,    13, 14637,   220],\n",
            "        [  464,  3942,  5537,  4139,  1770,    13, 14637,   220]])\n",
            "The Indian Prime Minister Mr. Modi \n",
            "--------------------------------------------------------------------------------\n",
            "Response 1:  has been invited to the White House in the same day, but he was not there.\n",
            " It is not clear if he is a guest, or if he is an official of the country, or if he is a guest.\n",
            " \n",
            "--------------------------------------------------------------------------------\n",
            "Response 2:  (pictured) has been named as the new Prime Minister of India.\n",
            "The new PM will be named by the Indian Prime Minister of India, and the Prime Minister will be chosen by all India citizens.\n",
            "In a letter to The Indian Government\n",
            "--------------------------------------------------------------------------------\n",
            "Response 3:  has made a strong statement on his government, that the  Modi government is in 1947, and has made a strong statement on the issue of India's 1947 Independence. The Prime Ministership of a nation  of the United States  United\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🎉 Hopefully, the answers from this model made some sense!\n",
        "\n",
        "If you find that the response is messy, this is in part because the model is spewing out words like a firehose. In practice, ChatGPT does additional tuning to make sure its responses are more natural.\n",
        "\n",
        "***So what is going on when a prompt is entered into the model?***\n",
        "\n",
        "We'll be going through a guided tutorial which we call **\"The life of a prompt\"**. We will take you through all the steps that a prompt goes through before the response is generated."
      ],
      "metadata": {
        "id": "nOVSTqsD_I46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Input preprocessing (~15 min)\n",
        "\n",
        "You'll notice in our function ```generate_text``` (the one provided a couple cells up, not in ```model.py```) that we do two steps before feeding the prompt into the model: (1) tokenization, (2) reshaping.\n",
        "\n",
        "(1) Tokenization is the process of breaking down free text into individual units (tokens). Tokens can be words like \"coffee\", \"cell\", or \"search\". They can also be subwords, such as the word \"psychology\" broken into \"psycho\" and \"logy\". This is what ```tokenize(prompt)``` does.\n",
        "\n",
        "In the cell below, we'll be using a tokenizer that's a little more understandable. (Read more about it [here](https://huggingface.co/transformers/v4.2.2/main_classes/tokenizer.html)).\n",
        "\n",
        "**TODO**: Run the line below to load the tokenizer.\n"
      ],
      "metadata": {
        "id": "ooR3-rNJ8Qod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "autotokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "oZC55D0MTP8M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "e045a46c076f46f19c9b5089f751e53a",
            "4ee36d577962455a87a4d8f305f3338d",
            "6c01dd9175574203b886f1e5749b7cd3",
            "225fb4bbd67841c597e3647cb6af9d28",
            "b9471f3196934ffeb51d1c0e6c37211f",
            "76ccbbe836dd425cafb8e9b8667d23f2",
            "b47b9acb39fb4c86bcf72ca3a5999fb4",
            "014a5c20159d46b1a411985d880e17f3",
            "08e63fe60a5c4c74a84feeef926735b6",
            "0d0bd924024445e48d23736159aaefba",
            "8304e9a8f3214cf196fda75b9c7d2ba3",
            "d5af5635bf32445cba4cc7c40baa9aa5",
            "82db5b111c5941239986db846a1b72ba",
            "ab590417cab84be2bf2250272ba1bd25",
            "9d1f08ff21ca45818553936ad837b853",
            "e753920de7774bb597da88426d14700c",
            "04bea70e4709434a947593603bf89dfa",
            "0713f077f03f49ac8b6d7c018f9c1826",
            "97a1edf2304b4084bdb5feaf04dfb6d0",
            "a01129a4638744e5850a492f2c2e42fb",
            "07a635a17ab24716a7701257513c794d",
            "6c901c3694454d8fbfafdd83fadad730",
            "afd8b0c38dcf421db8466109a330b3ea",
            "0d751cfb6ebc49019902fa9e4ba30aff",
            "28a92d6d2cf84da789bb2c70f513b7c2",
            "f1bb0fed260c4924a9ee310763b05fde",
            "3629d73293934ff899f366e2091f38a7",
            "b43a40ca9b304ed89ad85a2bc2b54d33",
            "9858098e9aaa4c879af6d65c73caa6a4",
            "c5f943b0ef7e449aa6f0748097c9c29b",
            "2d2f1c08c9fd4fb6af9bd4b50c30c649",
            "4429aa9fdb984c61be820f113a404089",
            "2cb9959530994295b25f35bb0a185877",
            "8ef725b356a948718f076bb64b25ce52",
            "241da360870f4a3199a559801d78ac7f",
            "ac06eddcd78d46daba8cdd9bd3250605",
            "df786e7cd80a46e1bd66762d3988b5bc",
            "af6327506f4d4e6e8f6afb6ae2abd419",
            "ab9ffa99f5da47edbc239f3229f3b251",
            "c086f4da226f43628d88e4cbe02b8aa7",
            "e618f3231e9240619a72a652179a1c93",
            "9f0e5dd0b7b145aba5dba8932b40e719",
            "057ca7b6b60e4081aa86f00cf5101627",
            "0d12c31cef644922a25e427621a7a82d"
          ]
        },
        "outputId": "2868e1a5-fdc7-4379-aa8a-7e038ef04d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e045a46c076f46f19c9b5089f751e53a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5af5635bf32445cba4cc7c40baa9aa5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afd8b0c38dcf421db8466109a330b3ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ef725b356a948718f076bb64b25ce52"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO**: Then, try a few different input strings to see how tokenization works:"
      ],
      "metadata": {
        "id": "KugMwyvjPall"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try changing input_string with a few of your own sentences!\n",
        "input_string = \"Ethiopian coffee tastes best with 10 minutes of brewing.\"\n",
        "\n",
        "autotokenizer.tokenize(input_string)"
      ],
      "metadata": {
        "id": "Z7sy0LAYTThZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35f9fb2-222d-426d-c79e-f6ddc8db5f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ethiopian',\n",
              " 'coffee',\n",
              " 'tastes',\n",
              " 'best',\n",
              " 'with',\n",
              " '10',\n",
              " 'minutes',\n",
              " 'of',\n",
              " 'brewing',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you try a word like \"enumeration\", you'll notice the tokens are ['en', '##ume', '##ration']. The double hash \"##\" is used to indicate subwords that are part of larger words.\n",
        "\n",
        "This symbol is used by **Byte Pair Encoding (BPE)**, which is commonly used in NLP tasks. You'll also notice that it removes capitalization since it doesn't affect word meanings in most cases. (This is what the uncased means in `bert-base-uncased`).\n",
        "\n",
        "The next step is to convert tokens into input ids: Each token is mapped to an identification number in the overall vocabulary.\n",
        "\n",
        "**TODO**: In the cell below, find out what the input id for the word \"coffee\" is. Also, figure out what the size of the vocabulary is."
      ],
      "metadata": {
        "id": "QcbWDYVmUW8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You'll need the vocab first.\n",
        "vocab = autotokenizer.get_vocab()\n",
        "\n",
        "# Grab the input id for 'coffee'\n",
        "coffee_vocab_id = vocab.get(\"coffee\")\n",
        "vocab_length = len(vocab)\n"
      ],
      "metadata": {
        "id": "HEV8lyGR0zyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coffee_vocab_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VX1hLBm9Rzb",
        "outputId": "975b9875-2ea7-4336-bff1-6fd2cbf0f409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4157"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.1', tuple([coffee_vocab_id, vocab_length]))"
      ],
      "metadata": {
        "id": "Oq73COrzWT2y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "21525470-5370-481f-a086-53994581c4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Easy enough, right? The tokenizer maps each prompt to its tokens, and then mapping those tokens to their input ids.\n",
        "\n",
        "Next, we are just left with reshaping the input.\n",
        "\n",
        "There's not too much to say about reshaping except for the fact that the line ```x = tokenizer(prompt).expand(num_samples, -1)``` has the ```expand``` component just to repeat the same prompt ```num_samples``` of times, each time aiming to get a different response to the prompt. (Think of it as a different \"try\" each time).\n",
        "\n",
        "___\n"
      ],
      "metadata": {
        "id": "KNGf5FNtXwag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Embeddings (~45 min)\n",
        "\n",
        "Scroll to line 283 in ```model.py```, where you'll find the function ```generate``` (different than the ```generate_text``` function we just worked with.) Try reading over this code to get a high-level understanding.\n",
        "\n",
        "The core of this function is found in line 293:\n",
        "\n",
        "```logits, _ = self(idx_cond)```.\n",
        "\n",
        "The self function calls ```forward```. In the ```forward``` function, you will find on line 267 our first focus point:\n",
        "\n",
        "```tok_emb = self.transformer.wte(idx)```\n",
        "\n",
        "Here, ```wte``` stands for word-token embedding.\n",
        "\n",
        "**TODO**: In the cell below, try running a sample prompt through this layer. Remember to first tokenize and reshape the prompt!\n",
        "\n"
      ],
      "metadata": {
        "id": "fCQRp6lZaDgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'Into the rabbit hole we go'\n",
        "x = autotokenizer.tokenize(prompt)\n",
        "x_input_ids = [vocab.get(word) for word in x]\n",
        "x_input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sfy5YyH-Q95",
        "outputId": "17ccd267-e396-4a45-feac-c0052296d776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2046, 1996, 10442, 4920, 2057, 2175]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the prompt is tokenized and reshaped\n",
        "prompt = 'Into the rabbit hole we go'\n",
        "x = tokenizer(prompt).expand(1,-1)\n",
        "print(x)\n",
        "\n",
        "# Pass x through the model.transformer.wte function\n",
        "x_embedding = model.transformer.wte(x)\n",
        "\n",
        "print(x_embedding.size())"
      ],
      "metadata": {
        "id": "vcUacS5X02Xd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3899f9e-09c9-4793-ae50-348cbf4e6906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5317,    78,   262, 22746,  7604,   356,   467]])\n",
            "torch.Size([1, 7, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you notice about the size of ```x_embedding``` vs ```x```?\n",
        "What dimension has grown?\n"
      ],
      "metadata": {
        "id": "TU6kxlT9k084"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code defines ```model.transformer.wte```:\n",
        "\n",
        "```wte = nn.Embedding(config.vocab_size, config.n_embd)```\n",
        "\n",
        "An embedding layer is used, which you can learn more about [here](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html).\n",
        "\n",
        "**TODO**: To familiarize yourself with embedding layers, initialize an ```nn.Embedding``` layer with ```num_embeddings = 10``` and ```embedding_dim = 5```. Then, come up with an input, ```in_x```, that produces an output of size (2, 4, 5) after it's passed through this embedding layer.\n",
        "\n",
        "Here are a couple hints:\n",
        "1. ```num_embeddings``` refers to the highest number any index can be.\n",
        "2. Look into Pytorch tensor type ```torch.LongTensor```."
      ],
      "metadata": {
        "id": "M_oy9iCxgHzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embedding layer\n",
        " #10 is the vocab size,\n",
        " #5 is the embedding dimension\n",
        "emb_layer = nn.Embedding(10,5)\n",
        "# Create input that produces output of size (2, 4, 5)\n",
        "T=4\n",
        "D=5\n",
        "n_samples=2\n",
        "\n",
        "#creating an input tensor where the vector or ids are between the vocublary indices <10 in this case\n",
        "in_x =torch.tensor([[1, 2, 3, 4],\n",
        "                       [5, 6, 7, 8]])\n",
        "\n",
        "\n",
        "out_x = emb_layer(in_x)\n",
        "out_x.size()"
      ],
      "metadata": {
        "id": "88bWKJG_4HZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba28318-390b-4a6b-c344-062cc27af1e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.2', out_x)"
      ],
      "metadata": {
        "id": "81NgnREMx3ma",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "fb0e5748-2a2e-4c4b-e6b1-69e48c2d0033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! So what does this all mean?\n",
        "\n",
        "In the shape (2, 4, 5), the 2 refers to the number of samples. For each sample, there is a (4, 5) tensor that represents the prompt. The 4 refers to the length of each prompt (number of tokens), and the final dimension 5 refers to the fact that each token is represented by a length-5 vector.\n",
        "\n",
        "**In a nutshell**:\n",
        "\n",
        "*Token -> nn.Embedding -> vector of size ```embedding_dim```*\n",
        "\n",
        "```nn.Embedding``` is a trainable layer, meaning that as the model sees more data, the exact way in which it associates the embeddings to each token changes.\n",
        "\n",
        "Let's see an example of this.\n",
        "\n",
        "**TODO**:\n",
        "\n",
        "In the cell below, create your own ```nn.Embedding``` layer that has the same number of input and output dimensions as ```model.transformer.wte```. Hint: You can find this out by just printing the object itself out."
      ],
      "metadata": {
        "id": "tNFQZF25yXmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.transformer.wte"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8DinNbPG38E",
        "outputId": "585c6682-c87f-431d-d04c-0e747c3e9651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50257, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7e26cdyjG3ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the embedding layer\n",
        "embedding_dim =768\n",
        "num_embeddings =50257\n",
        "untrained_embedding = nn.Embedding(num_embeddings, embedding_dim)\n"
      ],
      "metadata": {
        "id": "cHhgDPGH82fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.3', untrained_embedding)"
      ],
      "metadata": {
        "id": "xgrFV_N084FX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "c5f95fd3-886d-466b-8142-4e70edba5851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A great gutcheck for this is to ask yourself what the first dimension refers to in the context of the tokenizer.\n",
        "\n",
        "Next, let's take two similar words and find out how well it associates them together **before any training**.\n",
        "\n",
        "To measure the similarity between two embedding vectors, we'll be using a score called cosine similarity (which is ```F.cosine_similarity``` in PyTorch) to compare the embeddings. Very similar embeddings will have a cosine similarity closer to 1, and very dissimilar embeddings will have cosine similarity closer to 0. **Hint: You will need to use the ```dim``` argument to compare the right dimension (the one with 768).**\n",
        "\n",
        "Finally, populate ```similarity_untrained``` with the cosine similarity as a numpy float. **You'll need to turn a torch tensor into numpy for this!** (Also, think about which dimension actually has the answer you want if you're running into dimension issues).\n"
      ],
      "metadata": {
        "id": "vP0My4VV8wgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tokenizer to tokenize 'dog' and 'canine'\n",
        "word1 = \"dog\"\n",
        "word2 = \"canie\"\n",
        "\n",
        "# Extract embeddings\n",
        "word_1_tokenized = tokenizer(word1).expand(1,-1)\n",
        "word_2_tokenized = tokenizer(word2).expand(1,-1)\n",
        "word1_emb = untrained_embedding(word_1_tokenized)\n",
        "word2_emb = untrained_embedding(word_2_tokenized)"
      ],
      "metadata": {
        "id": "YmV0oJxqqofg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.squeeze(word1_emb).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVi52_hJsUth",
        "outputId": "035e2e12-a765-40da-81d5-1bc48f860bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(word2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gn8vWk0u8YU",
        "outputId": "981604bf-579f-40e9-e896-4f530003b131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5171,  494]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tokenizer to tokenize 'dog' and 'canine'\n",
        "word1 = \"dog\"\n",
        "word2 = \"canie\"\n",
        "\n",
        "# Extract embeddings\n",
        "word_2_tokenized = tokenizer(word2)\n",
        "word_1_tokenized = tokenizer(word1)\n",
        "\n",
        "print(word_2_tokenized)\n",
        "word_2_tokenized\n",
        "\n",
        "word1_emb = untrained_embedding(word_1_tokenized)\n",
        "word2_emb = untrained_embedding(word_2_tokenized)\n",
        "word2_emb = torch.mean(word2_emb, dim=1, keepdim=True)\n",
        "\n",
        "#shapes\n",
        "print(word1_emb.shape)\n",
        "print(word2_emb.shape)\n",
        "\n",
        "#normalized\n",
        "word1_emb_normalized =torch.squeeze(word1_emb).reshape(1,-1)\n",
        "word2_emb_normalized =torch.squeeze(word2_emb).reshape(1,-1)\n",
        "\n",
        "print(word1_emb_normalized.shape)\n",
        "\n",
        "# Compute the cosine similarity between word1_emb and word2_emb\n",
        "similarity_untrained = F.cosine_similarity(word1_emb_normalized, word2_emb_normalized)\n",
        "similarity_untrained = similarity_untrained.detach().numpy() # Convert to numpy float\n",
        "\n",
        "print(similarity_untrained)"
      ],
      "metadata": {
        "id": "N9W1rQW74j3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efb2dc2-75e5-42b9-d20a-cdfcedb3fd6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5171,  494]])\n",
            "torch.Size([1, 1, 768])\n",
            "torch.Size([1, 1, 768])\n",
            "torch.Size([1, 768])\n",
            "[0.01145177]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO**:\n",
        "Next, you will be using the ```wte``` (word token embedding) layer from the model that has already been trained. The goal is to notice the difference before and after model training. The embedding produced after training should be much better than random."
      ],
      "metadata": {
        "id": "Ep9W-XJQGBwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tokenizer to tokenize 'dog' and 'canine'\n",
        "word1 = \"dog\"\n",
        "word2 = \"canie\"\n",
        "\n",
        "# Extract embeddings\n",
        "word_2_tokenized = tokenizer(word2)\n",
        "word_1_tokenized = tokenizer(word1)\n",
        "\n",
        "print(word_2_tokenized)\n",
        "word_2_tokenized\n",
        "\n",
        "word1_emb = model.transformer.wte(word_1_tokenized)\n",
        "word2_emb = model.transformer.wte(word_2_tokenized)\n",
        "word2_emb = torch.mean(word2_emb, dim=1, keepdim=True)\n",
        "\n",
        "#shapes\n",
        "print(word1_emb.shape)\n",
        "print(word2_emb.shape)\n",
        "\n",
        "#normalized\n",
        "word1_emb_reshaped =torch.squeeze(word1_emb).reshape(1,-1)\n",
        "word2_emb_reshaped =torch.squeeze(word2_emb).reshape(1,-1)\n",
        "\n",
        "print(word1_emb_normalized.shape)\n",
        "\n",
        "# Compute the cosine similarity\n",
        "similarity_trained = F.cosine_similarity(word1_emb_reshaped, word2_emb_reshaped)\n",
        "similarity_trained = similarity_trained.detach().numpy() # Convert to numpy float\n",
        "\n",
        "print(similarity_trained)"
      ],
      "metadata": {
        "id": "lT1kzDZH53rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b91022d-da98-4b59-b9e8-00d5e4aeb7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5171,  494]])\n",
            "torch.Size([1, 1, 768])\n",
            "torch.Size([1, 1, 768])\n",
            "torch.Size([1, 768])\n",
            "[0.33958447]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.4', tuple([similarity_untrained, similarity_trained]))"
      ],
      "metadata": {
        "id": "3eW5V2HNG7fU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "34b75d7e-35d6-4e96-ae0d-40bd15c4db83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! If done correctly, you should find that the random initialization has a very low similarity score between two related words (\"dog\", \"canine\").\n",
        "\n",
        "After training, the model's ```wte``` layer associates similar words more closely. Another way to look at this is that the model's embeddings represent \"meaning\" much more strongly."
      ],
      "metadata": {
        "id": "HNC24ORnHYA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try one more exercise here. Rather than find the embedding for a single word, can we extract the embedding for a whole sentence?\n",
        "\n",
        "Because the embedding layer will produce a 768-sized vector for each token, we will need to find a way to \"squash\" that into a fixed-length vector. One common method is just to take the average value along each of the 768 dimensions.\n",
        "\n",
        "**TODO**:\n",
        "In the cell below, tokenize the prompt and extract the embeddings. What are the dimensions of the embeddings? Compute the mean embedding."
      ],
      "metadata": {
        "id": "TlkMm6WY6Q8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Dogs are one of the most popular pets in the world.\"\n",
        "\n",
        "# Tokenize sentence and extract embedding from the trained layer\n",
        "sentence_emb_tokenized = tokenizer(sentence)\n",
        "print(sentence_emb_tokenized.shape)\n",
        "sentence_emb = model.transformer.wte(sentence_emb_tokenized)\n",
        "print(sentence_emb.shape)\n",
        "sentence_emb = torch.mean(sentence_emb, dim=1, keepdim=True)\n",
        "print(sentence_emb.shape)\n",
        "\n",
        "# Compute the mean of the layer across all words in the sentence.\n",
        "mean_emb = torch.squeeze(sentence_emb).reshape(1,-1)\n",
        "print(mean_emb.shape)"
      ],
      "metadata": {
        "id": "YFptIxYN-aCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecffdc5b-0248-4537-fbd4-0f7b876b8655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 13])\n",
            "torch.Size([1, 13, 768])\n",
            "torch.Size([1, 1, 768])\n",
            "torch.Size([1, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.5', mean_emb)"
      ],
      "metadata": {
        "id": "JW2Myu8296eC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "b27cccf6-5bd4-49d0-9489-f031d71a1d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test out how well this works on the task of comparing sentence. Below are three sentences. The first sentence is a linear regression formula, and the second and third are statements about dogs. The idea is that the cosine similarity between sentence B and sentence C should be higher than the cosine similarity between sentence A and B or A and C.\n",
        "\n",
        "**TODO**: Run the following cell. Then, compute the cosine similarities below (as numpy floats)."
      ],
      "metadata": {
        "id": "4A_6Yjfm6yyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentence and extract embedding from the trained layer\n",
        "def sent_embedding(sentence):\n",
        "    sentence_emb_tokenized = tokenizer(sentence)\n",
        "    sentence_emb = model.transformer.wte(sentence_emb_tokenized)\n",
        "    sentence_emb = torch.mean(sentence_emb, dim=1, keepdim=True)\n",
        "    # Compute the mean of the layer across all words in the sentence.\n",
        "    mean_emb = torch.squeeze(sentence_emb).reshape(1,-1)\n",
        "    return mean_emb\n",
        "\n",
        "def similarity(sentence1, sentence2):\n",
        "  # Compute the cosine similarity\n",
        "  sentence1 = F.normalize(sentence1, dim=-1)\n",
        "  sentence2 = F.normalize(sentence2, dim=-1)\n",
        "  similarity_trained = F.cosine_similarity(sentence1, sentence2)\n",
        "  similarity_trained = similarity_trained.detach().numpy() # Convert to numpy float\n",
        "  return  similarity_trained\n",
        "\n",
        "\n",
        "sentenceA = \"y = β₀ + β₁x₁ + β₂x₂ + … + βₚxₚ + ε\"\n",
        "sentenceB = \"Dogs are one of the most popular pets in the world.\"\n",
        "sentenceC = \"There are over 300 different breeds of dogs.\""
      ],
      "metadata": {
        "id": "S4kiUPpX3Sjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract mean sentence embeddings for each sentence.\n",
        "embA = sent_embedding(sentenceA)\n",
        "embB = sent_embedding(sentenceB)\n",
        "embC = sent_embedding(sentenceC)\n",
        "\n",
        "# Compute the cosine similarity for each pair of sentences and convert to a numpy float\n",
        "ABsim = similarity(embA, embB)\n",
        "BCsim = similarity(embB, embC)\n",
        "ACsim = similarity(embA, embC)\n",
        "\n",
        "print(ABsim, BCsim, ACsim)"
      ],
      "metadata": {
        "id": "4Xshnlvy_T31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c67328-2f35-4cf1-b52f-ca527fbf8065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5131977] [0.84531766] [0.6010431]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.6', tuple([ABsim, BCsim, ACsim]))"
      ],
      "metadata": {
        "id": "t1HXSUvu-_IR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "9410cdc7-c30a-4d92-aab3-98b8b9656263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see if this works on a larger scale. In the variable ```SENTENCES``` is a list of 100 sentences. 90 of these sentences are about cats or dogs, while 10 are about statistics.\n",
        "\n",
        "\n",
        "**TODO**: Can you use sentence embeddings to figure out which 10 are about statistics **without looking at them**?\n",
        "\n",
        "This part is open-ended. In general terms, you should: (1) extract and compute the mean embeddings for each sentence. (2) Compare the embeddings with one another. For example, you could try a [clustering method](https://scikit-learn.org/stable/modules/clustering.html)!\n",
        "\n",
        "Once you finish, populate ```outlier_idx``` with a list of the indices (a numpy array) in ```SENTENCES``` which contain the statistics sentences."
      ],
      "metadata": {
        "id": "87NjfVJS74gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SENTENCES[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "uEMQXCAf24yo",
        "outputId": "1d4dd864-8fde-4d3c-fe3a-291346a5e73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dogs are often used in therapy to help people with emotional and physical challenges.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here\n",
        "import pandas as pd\n",
        "sentence_example = SENTENCES[0]\n",
        "\n",
        "sentence_embeddings = [torch.squeeze(sent_embedding(sentence)).detach().numpy() for sentence in SENTENCES]\n",
        "sent_df = pd.DataFrame(sentence_embeddings)\n",
        "print(sent_df.shape)\n",
        "\n",
        "#K-means clustering\n",
        "from sklearn.cluster import KMeans\n",
        "# Perform K-means clustering\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(sent_df)\n",
        "\n",
        "# Get the cluster labels\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# Add the cluster labels to the DataFrame\n",
        "sent_df['Cluster'] = cluster_labels\n",
        "\n",
        "# Print the DataFrame with cluster labels\n",
        "print(sent_df.groupby(['Cluster']).size())\n",
        "\n",
        "outlier_idx = sent_df[sent_df['Cluster']==0].index"
      ],
      "metadata": {
        "id": "kMxeyyyPE4w5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01bc9819-f61a-4889-dc6a-f4abcc35414a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 768)\n",
            "Cluster\n",
            "0    10\n",
            "1    90\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.7', outlier_idx)"
      ],
      "metadata": {
        "id": "XwyS_Tj3FH1F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "a52ab2b6-de2f-4c24-a1a5-946e81a17d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will be covering the ```block```, which is referenced on line 148 and defined starting line 73:\n",
        "\n",
        "Each block consists of two parts: ```self.attn``` and ```self.mlpf```. We'll focus on ```self.attn```, as ```self.mlpf``` is conceptually just an MLP.\n",
        "\n",
        "The attention mechanism is the core of what makes a Transformer, a Transformer.\n"
      ],
      "metadata": {
        "id": "qZlD8CLwcwsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Self-Attention (~30 min)\n",
        "\n",
        "If you  examine ```model.transformer.h```, you will see a list of blocks, which each contain their own ```attn``` layer.\n",
        "\n",
        "Let's say we have a sentence: \"All the dogs bark at John for food\". Intuitively, we understand that the word \"bark\" refers to the dogs, rather than John. Does the model understand the same?\n",
        "\n",
        "We will be testing this out in a little experiment below.\n",
        "\n",
        "First, tokenize the sentence and store its embedding using ```wte``` (use only one sample).\n"
      ],
      "metadata": {
        "id": "BYl2teB8_vgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_string = 'All the dogs bark at John for food'\n",
        "\n",
        "# Tokenize and extract embeddings\n",
        "x = tokenizer(input_string)\n",
        "x_emb = model.transformer.wte(x)"
      ],
      "metadata": {
        "id": "GCvGrl2wAjH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO**:\n",
        "\n",
        "Next, go to line 29 where ```CausalSelfAttention``` is defined.\n",
        "\n",
        "We want to extract the attentions directly to see what's going on. After line 64, add ```return att```. This should come after ```att = F.softmax(att, dim=-1)``` and before ```att = self.attn_dropout(att)```. Next, comment out line 63: ```att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))```. This is done so to save computation, but we want the whole attention matrix for interpretability purposes.\n",
        "\n",
        "Save ```model.py``` and return back to this notebook.\n",
        "\n",
        "Now, in the cell below, do the following steps:\n",
        "\n",
        "1. First, examine ```model.transformer.h```. You will notice a ```ModuleList``` containing 12 blocks. We'll only be using the first block in this list. Pass the tokenized sentence ```x_emb``` into this first block and extract the attention matrix for your sentence. The output should have shape 1x12x8x8, where 12 refers to the number of attention heads. (Note: the number of blocks is not the same as the number of attention heads, they just happen to be both 12!) Then, take the mean attention across all 12 attention heads so that you are left with a tensor of size 8x8. Hint: You can convert a tensor of dimension (1, 8, 8) to dimension (8, 8) by just calling ```.squeeze(0)``` on that tensor."
      ],
      "metadata": {
        "id": "P_ec_LeXsISu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.transformer.h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F98_NmOwOed_",
        "outputId": "7b07ab1f-e598-4608-9e21-e3c35a32afc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0-11): 12 x Block(\n",
              "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (attn): CausalSelfAttention(\n",
              "      (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
              "      (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (mlp): ModuleDict(\n",
              "      (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (act): NewGELU()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_block = model.transformer.h[0]\n",
        "first_block"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XtL6CXAPPOz",
        "outputId": "2a45b08d-43aa-4016-fec5-3f3eea9e86b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Block(\n",
              "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (attn): CausalSelfAttention(\n",
              "    (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
              "    (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (mlp): ModuleDict(\n",
              "    (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    (act): NewGELU()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to access the casual attention module\n",
        "first_block.attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEhqVnLmRjFx",
        "outputId": "270d49a5-590f-4f88-f072-a95f1c11c868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CausalSelfAttention(\n",
              "  (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
              "  (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I3ME9S6Peqt",
        "outputId": "3491eeb9-35d4-4b28-92cf-449b744006b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using only the first block, extract the attention matrix and take the mean over all 12 attention heads\n",
        "attn_mat = first_block.attn(x_emb)\n",
        "attn_mat.shape"
      ],
      "metadata": {
        "id": "2JHD2LUdDKdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d9fec6-05ae-4ea9-c5c3-ffbf5847b9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 12, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_attention_heads = torch.mean(attn_mat, dim=1)\n",
        "mean_attention_heads.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvV03v1iPKW4",
        "outputId": "5ac29942-97e9-4d2a-b2bf-d53d54ef44f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_mat = mean_attention_heads.squeeze()\n",
        "attn_mat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVYtihNJSC11",
        "outputId": "344d1aa1-7327-4e1b-fa26-ea471a2e1a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_mat\n",
        "#'All the dogs bark at John for food'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvM3S2R5SRhB",
        "outputId": "05e58168-4a32-469c-f41a-c238656f5f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4085, 0.0942, 0.0538, 0.0511, 0.1120, 0.1038, 0.1199, 0.0567],\n",
              "        [0.1316, 0.2520, 0.0633, 0.0660, 0.1358, 0.0958, 0.1698, 0.0857],\n",
              "        [0.0581, 0.0671, 0.3571, 0.1113, 0.0765, 0.0737, 0.0908, 0.1653],\n",
              "        [0.0615, 0.0720, 0.1572, 0.3954, 0.0802, 0.0531, 0.0915, 0.0892],\n",
              "        [0.1191, 0.0989, 0.0622, 0.1150, 0.2980, 0.0749, 0.1546, 0.0772],\n",
              "        [0.1031, 0.0728, 0.0643, 0.0653, 0.0798, 0.4705, 0.0888, 0.0554],\n",
              "        [0.1084, 0.1066, 0.0574, 0.0898, 0.1317, 0.0750, 0.3462, 0.0848],\n",
              "        [0.0691, 0.0705, 0.1426, 0.0611, 0.0895, 0.0538, 0.0908, 0.4224]],\n",
              "       grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.8', attn_mat)"
      ],
      "metadata": {
        "id": "1zYYJhNNOVhe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "b364c792-b4ea-406a-d42c-a2119bdd0717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. At this point, you can also visualize the attention matrix by using the line ```plt.imshow(attn_mat)```. Next, we're interested in what the word \"bark\" is paying attention to. For each 8x8 tensor, extract the row that corresponds to the word \"bark\" (think about what index this is from the prompt). You should be left with a tensor of length 8."
      ],
      "metadata": {
        "id": "6BEgp60zEGGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to visualize what the attention matrix looks like\n",
        "plt.imshow(attn_mat.detach().numpy())"
      ],
      "metadata": {
        "id": "zjYCnt1dDNOg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "31376cc0-b152-4b08-ef99-0ce60170a038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f47eda5b790>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract just the row for the word 'bark'\n",
        "attn_row = attn_mat[3]\n",
        "attn_row"
      ],
      "metadata": {
        "id": "VWE7s7cROg9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4696fed3-20e2-4190-dfc1-f688f6fe708d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0615, 0.0720, 0.1572, 0.3954, 0.0802, 0.0531, 0.0915, 0.0892],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.9', attn_row)"
      ],
      "metadata": {
        "id": "1_PfU3gfOiNL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "58a28b1e-3fa5-4abd-d01e-c03b515e53e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Finally, return a dictionary that has each word in the sentence as a key and its attention score as the value (as a numpy float). It should look something like ```{'All': 0.01, 'the': 0.22, ...}```\n",
        "\n",
        "Which word does \"bark\" attend to the most (besides \"bark\")? Between the dog and John, which word does \"bark\" attend more strongly towards?"
      ],
      "metadata": {
        "id": "F0exj5szLexv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Populate dictionary of words and values\n",
        "# Remember to convert the attention scores to a numpy float!\n",
        "input_string_words = input_string.split(\" \")\n",
        "attn_dict = {input_string_words[i]:attn_row[i] for i in range(len(attn_row))}"
      ],
      "metadata": {
        "id": "uV_HS0-mMnqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-lYZYoRW-tj",
        "outputId": "0a12d8bf-6175-49ed-d67e-c2f13716f1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'All': tensor(0.0615, grad_fn=<SelectBackward0>),\n",
              " 'the': tensor(0.0720, grad_fn=<SelectBackward0>),\n",
              " 'dogs': tensor(0.1572, grad_fn=<SelectBackward0>),\n",
              " 'bark': tensor(0.3954, grad_fn=<SelectBackward0>),\n",
              " 'at': tensor(0.0802, grad_fn=<SelectBackward0>),\n",
              " 'John': tensor(0.0531, grad_fn=<SelectBackward0>),\n",
              " 'for': tensor(0.0915, grad_fn=<SelectBackward0>),\n",
              " 'food': tensor(0.0892, grad_fn=<SelectBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If this check isn't working, just make sure 'dog' has the highest score (next to 'bark')\n",
        "#check('2.1.10', attn_dict)"
      ],
      "metadata": {
        "id": "AiGlPhuhO9jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try this for a sentence of your choice. (Sometimes, the tokenizer might split up a word into two pieces, so pick your sentences and attentions carefully)\n",
        "\n",
        "In the cell below, combine the code you wrote in the lines above and process the new input string to return the attention dictionary."
      ],
      "metadata": {
        "id": "qN2w2B3JLkiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sent2attn_matrix(sent):\n",
        "  x = tokenizer(sent)\n",
        "  x_emb = model.transformer.wte(x)\n",
        "  first_block = model.transformer.h[0]\n",
        "  attn_mat = first_block.attn(x_emb)\n",
        "  mean_attention_heads = torch.mean(attn_mat, dim=1)\n",
        "  attn_mat = mean_attention_heads.squeeze()\n",
        "  attn_row = attn_mat[0]\n",
        "  input_string_words = sent.split(\" \")\n",
        "  attn_dict = {input_string_words[i]:attn_row[i] for i in range(len(attn_row))}\n",
        "  return attn_dict\n",
        "\n",
        "\n",
        "\n",
        "input_string = 'I am a good boy'\n",
        "attn_dict = sent2attn_matrix(input_string)\n",
        "print(attn_dict)"
      ],
      "metadata": {
        "id": "GDhsjLqnRZAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2dcf011-e1ee-4a72-a92d-bad72952e986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'I': tensor(0.5120, grad_fn=<SelectBackward0>), 'am': tensor(0.1359, grad_fn=<SelectBackward0>), 'a': tensor(0.1481, grad_fn=<SelectBackward0>), 'good': tensor(0.1094, grad_fn=<SelectBackward0>), 'boy': tensor(0.0947, grad_fn=<SelectBackward0>)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check('2.1.11', attn_dict)"
      ],
      "metadata": {
        "id": "iN3tpUJKXwo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't worry if this part is a bit involved! Feel free to ask away on Slack. (Think through what each dimension is referring to at each step).\n",
        "\n",
        "Do the attention scores still make sense? It would be great to share your thoughts! (You can alter the block you are examining, or even the method of taking the average over all heads).\n",
        "\n",
        "At the end of the day, interpreting attention scores are a finicky business, so don't be discouraged if you aren't getting exactly what you're looking for!"
      ],
      "metadata": {
        "id": "kIYkhOngkJI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Outputs (~20 min)\n",
        "\n",
        "Together, the input preprocessing, embeddings, and self-attention are the key parts of a transformer. There are many other components that make it work, and we will conver some of them next week (and other parts, you can familiarize on your own).\n",
        "\n",
        "Finally, we'll focus on how the output is processed.\n",
        "\n",
        "Delete the ```return att``` line you've injected in script, and uncomment out line 63. Remember to save! Now, return to line 293: ```logits, _ = self(idx_cond)```. We can recreate this line below:"
      ],
      "metadata": {
        "id": "dTuTmES6AT4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run the line below!\n",
        "\n",
        "input_string = 'To make bread, first add'\n",
        "x = tokenizer(input_string)\n",
        "\n",
        "logits_orig, _ = model(x)"
      ],
      "metadata": {
        "id": "wP40C3o5xwR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIO7p3pTAkeI",
        "outputId": "0ebe7f0a-cbec-456b-da78-877d3467d9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2514,  787, 8509,   11,  717,  751]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_orig.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJhCv4cs_6Kq",
        "outputId": "81ae2e3a-bc4f-460a-f0a3-1c0ab2388791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 50257])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine the size of ```logits```. What does each dimension refer to?\n",
        "\n",
        "Next, we only want to know what the model's next word prediction is after the final word of our input. In the cell below, extract the logits from the last word."
      ],
      "metadata": {
        "id": "QlCvTtQPyAbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Just extract the last in the sequence. Think carefully about which dimension you are extracting from!\n",
        "logits = logits_orig[:, -1, :]"
      ],
      "metadata": {
        "id": "dByhQIEPRQ_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIquhlzVBEbg",
        "outputId": "f5479cbc-9afe-453e-fd9e-ae6a1d0b8e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 50257])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.12', logits)"
      ],
      "metadata": {
        "id": "bAey_PvFRjVQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "c6f6badf-fb7d-479b-d8e5-fdbe4ad8703a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below, apply the softmax layer to the logits. This makes it so that all the probabilities assigned to each vocab word sum to one."
      ],
      "metadata": {
        "id": "vqXEbxUJ0Qcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Just copy-paste line 301\n",
        "probs = F.softmax(logits, dim=1)\n",
        "probs[0:10]"
      ],
      "metadata": {
        "id": "fmUSZSsVSBGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab47540d-9aa5-4452-beb6-8c8bd16d0853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8.7109e-05, 4.3731e-05, 5.5828e-07,  ..., 8.1838e-09, 1.9897e-08,\n",
              "         1.6580e-05]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, compute the top ten predictions using ```torch.topk```. Then, populate a dictionary ```scores_dict``` where the keys are ten tokens and the values are their relative probabilities. The keys should be strings and the values should be numpy floats. You'll have to do some Pytorch tensor manipulation and data type conversions here! (Remember, use ```tokenizer.decode()``` to convert indices back into the words they refer to)"
      ],
      "metadata": {
        "id": "TtAaTQ9w1Ngk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(torch.tensor([262]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U3efu0jkEvEa",
        "outputId": "a142bf45-ab1e-4362-d91f-81fd92dd0d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract top 10 using torch.topk\n",
        "top_probs, top10 = torch.topk(probs, k=10, dim=1)\n",
        "top_probs=top_probs.squeeze(0).detach().numpy()\n",
        "top10=top10.squeeze(0).detach().numpy()\n",
        "\n",
        "print(\"Top Probabilities Shape:\", top_probs.shape)\n",
        "print(\"Top Indices Shape:\", top10.shape)\n",
        "\n",
        "\n",
        "# Populate the dictionary\n",
        "scores_dict = {tokenizer.decode(torch.tensor([top10[i]])):top_probs[i] for i in range(len(top10))}"
      ],
      "metadata": {
        "id": "_m6CgwldTa37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8303584-7383-4860-cae2-fed7d1ebd712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Probabilities Shape: (10,)\n",
            "Top Indices Shape: (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(torch.tensor([top10[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ks8bNAigFU8v",
        "outputId": "21a4d14d-9b28-4268-a95e-8e059b2ad97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7AHbD8YDl6B",
        "outputId": "857050e6-fe60-495e-84a1-628bba6ed053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' the': 0.204424,\n",
              " ' a': 0.11020867,\n",
              " ' some': 0.057291437,\n",
              " ' 1': 0.03690852,\n",
              " ' flour': 0.026994199,\n",
              " ' to': 0.02638669,\n",
              " ' 2': 0.025335884,\n",
              " ' butter': 0.02435032,\n",
              " ' in': 0.017543495,\n",
              " ' your': 0.017139781}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.13', scores_dict)"
      ],
      "metadata": {
        "id": "ehobAIsSS5Fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "decb7451-15d3-4cf3-d477-712694448806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll notice in the code, each logit is divided by a temperature. This smooths out the predictions such that there is less of a relative difference between the logits for each word.\n",
        "\n",
        "Let's see how this affects the relative predicted probabilities.\n",
        "Now, divide logits by a constant ```temperature=1.5```. Repeat the same steps in as the previous question and produce ```scores_dict_temp```, which is the scores after using temperature 1.5."
      ],
      "metadata": {
        "id": "y6vy6nga2lmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits_temp, _ = model(x)\n",
        "logits = logits_temp[:, -1, :]\n",
        "probs = F.softmax(logits, dim=1)\n",
        "top_probs, top10 = torch.topk(probs, k=10, dim=1)\n",
        "top_probs=top_probs.squeeze(0).detach().numpy()\n",
        "top10=top10.squeeze(0).detach().numpy()\n",
        "\n",
        "print(\"Top Probabilities Shape:\", top_probs.shape)\n",
        "print(\"Top Indices Shape:\", top10.shape)\n",
        "\n",
        "\n",
        "# Populate the dictionary\n",
        "scores_dict_temp = {tokenizer.decode(torch.tensor([top10[i]])):top_probs[i] for i in range(len(top10))}"
      ],
      "metadata": {
        "id": "rMuIMdkzUQMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0685843e-57eb-44ca-90bb-50f9ee5ab516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Probabilities Shape: (10,)\n",
            "Top Indices Shape: (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_dict_temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tXdeNk-HnmN",
        "outputId": "048e9bfd-ec34-427a-cb20-6eb433f519d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' butter': 0.082397364,\n",
              " ' water': 0.066489086,\n",
              " ' salt': 0.0632457,\n",
              " ' flour': 0.054999564,\n",
              " ' the': 0.05380918,\n",
              " ' milk': 0.047890656,\n",
              " ' it': 0.029871732,\n",
              " ' yeast': 0.027709372,\n",
              " ' a': 0.024515454,\n",
              " ' sugar': 0.022190996}"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check('2.1.14', tuple([scores_dict, scores_dict_temp]))"
      ],
      "metadata": {
        "id": "k2oDjs8ZUdo8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "c36ba8e9-c778-4ab3-e022-5756b7622203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Correct! 🎉"
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that it does not change the relative order of probabilities.\n",
        "\n",
        "However, it will change their chance of being picked if we sample them at random.\n",
        "\n",
        "In the cell below, sample the next word using ```torch.multinomial```. After decoding the word, does the choice surprise you?\n",
        "\n",
        "Try running a few examples by changing ```num_samples``` to 10."
      ],
      "metadata": {
        "id": "jS0OeJEjznnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples=10\n",
        "sampled_indices = torch.multinomial(probs, num_samples, replacement=True)\n",
        "\n",
        "indices_list = sampled_indices.squeeze().tolist()\n",
        "\n",
        "for i in indices_list:\n",
        "  next_word=tokenizer.decode(torch.tensor([i]))\n",
        "  print(next_word)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g2b6V4QFVU1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74233e03-c45b-4183-f39f-edb25e7a7744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " water\n",
            " cheese\n",
            " the\n",
            " chopped\n",
            " the\n",
            " chopped\n",
            " water\n",
            " butter\n",
            " the\n",
            " the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_word = tokenizer.decode(torch.tensor([610]))\n",
        "next_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qhikY8EoIerp",
        "outputId": "e8fb1840-25e2-4c05-bc70-942a5af25364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' ar'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll notice that by sampling, we get a more diverse choice of words, but perhaps more random.\n",
        "\n",
        "In general, this is a trade-off for large language models -- we want more creativity, but it risks non-sense responses!\n",
        "___\n",
        "\n",
        "## Summary\n",
        "\n",
        "Congrats! You got through the main parts of the GPT model!\n",
        "\n",
        "Feel free to continue playing around with prompts from the questions in this assignment and see if any responses surprise you!"
      ],
      "metadata": {
        "id": "43mgu2J6zseY"
      }
    }
  ]
}