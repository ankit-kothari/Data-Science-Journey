{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Part 7: Classification with pytorch using distilBERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ9GSXQVL-h4"
      },
      "source": [
        "##GENERAL\n",
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "import csv\n",
        "import re\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Embedding, LSTM, Bidirectional, GlobalMaxPool1D, Input,BatchNormalization, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "\n",
        "##SKLEARN\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU02359_PKou",
        "outputId": "85d5c112-053b-47b7-9628-6f0425467bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLZBuFl4BD7z"
      },
      "source": [
        "##Loading in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YflJ2hoEPFHG",
        "outputId": "c9b1a756-cd2e-4ccd-d934-c15a88fad85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data = pd.read_csv('/gdrive/My Drive/data/amazon_products.csv')\n",
        "data = data.drop(columns=['Unnamed: 0'])\n",
        "data.info()"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 58828 entries, 0 to 58827\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   review           58828 non-null  object\n",
            " 1   clean_review     58828 non-null  object\n",
            " 2   review_category  58828 non-null  object\n",
            " 3   topic_category   58828 non-null  int64 \n",
            " 4   topic_name       58828 non-null  object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 2.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4KOK1OZPS3O",
        "outputId": "7a21f650-e418-442e-df61-4ef94980d927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data['topic_name'].unique()"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['books', 'video-quality', 'refund-and-return', 'movies', 'music',\n",
              "       'games'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwK6OooMBMJi"
      },
      "source": [
        "##Creating the Text to Categorical Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIAWL0z7PVKL",
        "outputId": "b564a680-85b5-4057-f0fc-1a3c47c3b3a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "data['topic_name']=data['topic_name'].astype('category')\n",
        "data['topic_name'].cat.categories\n",
        "print(data['topic_name'].cat.categories)\n",
        "data['topic_category_codes']=data['topic_name'].cat.codes.values\n",
        "data = data.drop(columns=['review','review_category','topic_category','topic_name'])\n",
        "data.head()"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['books', 'games', 'movies', 'music', 'refund-and-return',\n",
            "       'video-quality'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_review</th>\n",
              "      <th>topic_category_codes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this self published book want know read paragr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rather scratches insect droppings random pixel...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my experience got fm Amazon the dvd player rat...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ordered dvd received substitute received dvd o...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>disappointed performance it underpowered const...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        clean_review  topic_category_codes\n",
              "0  this self published book want know read paragr...                     0\n",
              "1  rather scratches insect droppings random pixel...                     5\n",
              "2  my experience got fm Amazon the dvd player rat...                     5\n",
              "3  ordered dvd received substitute received dvd o...                     5\n",
              "4  disappointed performance it underpowered const...                     4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuuZFD2wBSfH"
      },
      "source": [
        "##Tokeinze the data using distilBERT Embeddings and distilBERT pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hty3Jb_i5X3p"
      },
      "source": [
        "data=data.iloc[:,:]"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_9pTxXBiuTt",
        "outputId": "d7b374eb-79c9-4a19-c501-66f56e3ea4ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "data['topic_category_codes'].value_counts()"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    23020\n",
              "0    16273\n",
              "3     7768\n",
              "5     5203\n",
              "2     4855\n",
              "1     1709\n",
              "Name: topic_category_codes, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG8aFIeCPlgJ"
      },
      "source": [
        "data.to_csv('/gdrive/My Drive/data/pytorch_amazon_products_bert.csv')"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fidlnzQV7Jjd",
        "outputId": "5adfe27e-f438-4cd7-9a23-73aa49a664bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)\n",
        "model.cuda()"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertModel(\n",
              "  (embeddings): Embeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (layer): ModuleList(\n",
              "      (0): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (1): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (2): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (3): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (4): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (5): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VIPxY7CPhdy",
        "outputId": "c21daef8-b73f-405f-a2d6-a0132ee80e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "tokenized = data['clean_review'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "max_len = [len(sent) for sent in tokenized]\n",
        "max_len = max(max_len)\n",
        "padded = pad_sequences(tokenized, maxlen=75, padding='post', truncating=\"post\", dtype='long')\n",
        "print('Shape of data tensor:', padded.shape)\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "print('Shape of attention:', attention_mask.shape)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (58828, 75)\n",
            "Shape of attention: (58828, 75)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RLPAQskDs4-",
        "outputId": "0953bae5-40c6-4a40-e818-4128b193c583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgdbM2ED-Fg3"
      },
      "source": [
        "labels= data.iloc[:,1].values\n"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuQGitxhFaI1"
      },
      "source": [
        "## Creating the Traning, Test and Attention Mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U64Cjkbw8QVc"
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(padded, labels, \n",
        "                                                            random_state=2018, test_size=0.1, stratify=data.topic_category_codes.values)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_mask, padded,\n",
        "                                             random_state=2018, test_size=0.1, stratify=data.topic_category_codes.values)"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gg5Ypne-5aV",
        "outputId": "57bcf5f3-d5d8-4f55-f95f-f9445e4805a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_inputs"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101,  4299,  2246, ...,     0,     0,     0],\n",
              "       [  101,  6823,  1055, ...,     0,     0,     0],\n",
              "       [  101,  2310,  4149, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  2137, 10282, ...,     0,     0,     0],\n",
              "       [  101,  3728,  2657, ...,     0,     0,     0],\n",
              "       [  101,  2045,  2503, ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQX8ItRMYlos",
        "outputId": "15be87cd-7d08-4aff-911d-868197454f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_masks"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "espFVjrkaGqu",
        "outputId": "f58e8d01-cdff-4344-b137-cda37206349c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.bincount(train_labels)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14646,  1538,  4369,  6991, 20718,  4683])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1DeUx6YaVtn",
        "outputId": "f816ea5c-241a-48e0-a991-a52cc67312cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.bincount(validation_labels)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1627,  171,  486,  777, 2302,  520])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUs0ud6rFhxi"
      },
      "source": [
        "## Creating Dataloader objects "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-tNBIui-ef7"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M97521kY_nNV"
      },
      "source": [
        "batch_size = 32\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIA3TkAkfaIF",
        "outputId": "73ace853-6230-4798-f881-fc24f7f68466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dataloader"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fba8bc3b7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaL74mvWhzPA",
        "outputId": "98696e34-b8cc-4358-c443-c744967ced82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.parameters()"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7fb9f01661a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjQqtvgXF2yg"
      },
      "source": [
        "## Using Transfer Learning to convert Bert Tokens to Embeddings\n",
        "\n",
        "- Use only the embedding for [CLS] token which according to the original paper is an aggregate representation of the whole sentence used for classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3448_9nlwfN"
      },
      "source": [
        "features = []\n",
        "features_labels = []\n",
        "for batch in train_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "    last_hidden_states = model(b_input_ids, attention_mask=b_input_mask)\n",
        "    last_hidden_states= last_hidden_states[0][:,0,:].cpu().numpy()\n",
        "    features.append(last_hidden_states)\n",
        "    features_labels.append(b_labels.cpu().numpy())\n",
        "    "
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caJzMVlGmkoP",
        "outputId": "13fea905-700f-40ae-c633-af6a4e585fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "features_labels = np.asarray(features_labels)\n",
        "features_labels_list = [a for a in features_labels]\n",
        "features_labels = np.concatenate(features_labels_list, axis=0)\n",
        "features_labels.shape"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52945,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80S3jP71p00v",
        "outputId": "39a036ff-d458-48eb-d991-af3e438cd0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "features = np.asarray(features)\n",
        "feature_list = [a for a in features]\n",
        "features = np.concatenate(feature_list, axis=0)\n",
        "features.shape"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52945, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COddUCeqGVvA"
      },
      "source": [
        "## Creating a Multi Classification Model using BERT Embedding for Sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrdzHbDGuPzL",
        "outputId": "db7e97c2-003f-4f8b-8a66-4a047739055e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(768, activation='relu', kernel_initializer=tf.keras.initializers.glorot_normal(seed=None), input_shape=(768,)))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(39,kernel_initializer=tf.keras.initializers.glorot_normal(seed=None), activation='relu'))\n",
        "model.add(Dense(19,kernel_initializer=tf.keras.initializers.glorot_normal(seed=None), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 768)               590592    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 39)                29991     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 19)                760       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 19)                76        \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 6)                 120       \n",
            "=================================================================\n",
            "Total params: 621,539\n",
            "Trainable params: 621,501\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9BlyTHoHHmp"
      },
      "source": [
        "## Training the Classification Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ4iCf2LuU8s"
      },
      "source": [
        "import keras\n",
        "from keras import optimizers\n",
        "rms = keras.optimizers.RMSprop(lr=0.01, rho=0.9)\n",
        "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "sgd = optimizers.SGD(lr=0.01, clipnorm=1.)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuqJMQ3WutlJ"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(features, \n",
        "                                                  features_labels, \n",
        "                                                  test_size=0.15, \n",
        "                                                  random_state=42, \n",
        "                                                  stratify=features_labels)\n"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1at61Hsz71rz"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"/content/drive/My Drive/models/amazon_bert.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 20,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "# we put our call backs into a callback list\n",
        "callbacks = [earlystop, checkpoint]"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFkNwaTYuZCd",
        "outputId": "bbd7ea14-a5e4-40cc-e655-bdee144c6259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          batch_size=32, epochs=100, verbose=1,\n",
        "          callbacks=callbacks,\n",
        "          validation_data=(X_val, y_val))"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1391/1407 [============================>.] - ETA: 0s - loss: 0.4471 - accuracy: 0.8681\n",
            "Epoch 00001: val_loss improved from inf to 0.40775, saving model to /content/drive/My Drive/models/amazon_bert.h5\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4461 - accuracy: 0.8683 - val_loss: 0.4078 - val_accuracy: 0.8611\n",
            "Epoch 2/100\n",
            "1391/1407 [============================>.] - ETA: 0s - loss: 0.3326 - accuracy: 0.8944\n",
            "Epoch 00002: val_loss did not improve from 0.40775\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3329 - accuracy: 0.8944 - val_loss: 0.4446 - val_accuracy: 0.8685\n",
            "Epoch 3/100\n",
            "1393/1407 [============================>.] - ETA: 0s - loss: 0.3090 - accuracy: 0.8997\n",
            "Epoch 00003: val_loss improved from 0.40775 to 0.33981, saving model to /content/drive/My Drive/models/amazon_bert.h5\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3084 - accuracy: 0.8998 - val_loss: 0.3398 - val_accuracy: 0.8850\n",
            "Epoch 4/100\n",
            "1396/1407 [============================>.] - ETA: 0s - loss: 0.2973 - accuracy: 0.9031\n",
            "Epoch 00004: val_loss did not improve from 0.33981\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2971 - accuracy: 0.9031 - val_loss: 0.4224 - val_accuracy: 0.8707\n",
            "Epoch 5/100\n",
            "1403/1407 [============================>.] - ETA: 0s - loss: 0.2846 - accuracy: 0.9080\n",
            "Epoch 00005: val_loss did not improve from 0.33981\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2844 - accuracy: 0.9081 - val_loss: 0.3414 - val_accuracy: 0.8921\n",
            "Epoch 6/100\n",
            "1397/1407 [============================>.] - ETA: 0s - loss: 0.2750 - accuracy: 0.9092\n",
            "Epoch 00006: val_loss improved from 0.33981 to 0.31570, saving model to /content/drive/My Drive/models/amazon_bert.h5\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2749 - accuracy: 0.9092 - val_loss: 0.3157 - val_accuracy: 0.8970\n",
            "Epoch 7/100\n",
            "1393/1407 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.9117\n",
            "Epoch 00007: val_loss did not improve from 0.31570\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2666 - accuracy: 0.9117 - val_loss: 0.3192 - val_accuracy: 0.9015\n",
            "Epoch 8/100\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 0.2594 - accuracy: 0.9134\n",
            "Epoch 00008: val_loss improved from 0.31570 to 0.29689, saving model to /content/drive/My Drive/models/amazon_bert.h5\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2595 - accuracy: 0.9133 - val_loss: 0.2969 - val_accuracy: 0.9044\n",
            "Epoch 9/100\n",
            "1397/1407 [============================>.] - ETA: 0s - loss: 0.2542 - accuracy: 0.9165\n",
            "Epoch 00009: val_loss improved from 0.29689 to 0.29470, saving model to /content/drive/My Drive/models/amazon_bert.h5\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2543 - accuracy: 0.9166 - val_loss: 0.2947 - val_accuracy: 0.9054\n",
            "Epoch 10/100\n",
            "1397/1407 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9178\n",
            "Epoch 00010: val_loss improved from 0.29470 to 0.27964, saving model to /content/drive/My Drive/models/amazon_bert.h5\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2468 - accuracy: 0.9176 - val_loss: 0.2796 - val_accuracy: 0.9071\n",
            "Epoch 11/100\n",
            "1394/1407 [============================>.] - ETA: 0s - loss: 0.2393 - accuracy: 0.9197\n",
            "Epoch 00011: val_loss improved from 0.27964 to 0.27836, saving model to /content/drive/My Drive/models/amazon_bert.h5\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2392 - accuracy: 0.9196 - val_loss: 0.2784 - val_accuracy: 0.9116\n",
            "Epoch 12/100\n",
            "1405/1407 [============================>.] - ETA: 0s - loss: 0.2344 - accuracy: 0.9217\n",
            "Epoch 00012: val_loss did not improve from 0.27836\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2344 - accuracy: 0.9217 - val_loss: 0.2946 - val_accuracy: 0.9073\n",
            "Epoch 13/100\n",
            "1401/1407 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9230\n",
            "Epoch 00013: val_loss did not improve from 0.27836\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2303 - accuracy: 0.9231 - val_loss: 0.3524 - val_accuracy: 0.8910\n",
            "Epoch 14/100\n",
            "1402/1407 [============================>.] - ETA: 0s - loss: 0.2250 - accuracy: 0.9243\n",
            "Epoch 00014: val_loss did not improve from 0.27836\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.2253 - accuracy: 0.9241 - val_loss: 0.3075 - val_accuracy: 0.9071\n",
            "Epoch 15/100\n",
            "1400/1407 [============================>.] - ETA: 0s - loss: 0.2183 - accuracy: 0.9261\n",
            "Epoch 00015: val_loss did not improve from 0.27836\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2182 - accuracy: 0.9261 - val_loss: 0.3226 - val_accuracy: 0.9017\n",
            "Epoch 16/100\n",
            "1398/1407 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9275\n",
            "Epoch 00016: val_loss did not improve from 0.27836\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2138 - accuracy: 0.9274 - val_loss: 0.2981 - val_accuracy: 0.9059\n",
            "Epoch 17/100\n",
            "1397/1407 [============================>.] - ETA: 0s - loss: 0.2109 - accuracy: 0.9289\n",
            "Epoch 00017: val_loss did not improve from 0.27836\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2109 - accuracy: 0.9289 - val_loss: 0.2914 - val_accuracy: 0.9109\n",
            "Epoch 18/100\n",
            "1399/1407 [============================>.] - ETA: 0s - loss: 0.2054 - accuracy: 0.9307\n",
            "Epoch 00018: val_loss did not improve from 0.27836\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2056 - accuracy: 0.9306 - val_loss: 0.3234 - val_accuracy: 0.9032\n",
            "Epoch 19/100\n",
            "1395/1407 [============================>.] - ETA: 0s - loss: 0.2007 - accuracy: 0.9320\n",
            "Epoch 00019: val_loss did not improve from 0.27836\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2009 - accuracy: 0.9320 - val_loss: 0.3351 - val_accuracy: 0.8976\n",
            "Epoch 20/100\n",
            "1398/1407 [============================>.] - ETA: 0s - loss: 0.1964 - accuracy: 0.9344\n",
            "Epoch 00020: val_loss did not improve from 0.27836\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1969 - accuracy: 0.9342 - val_loss: 0.3293 - val_accuracy: 0.8986\n",
            "Epoch 21/100\n",
            "1398/1407 [============================>.] - ETA: 0s - loss: 0.1895 - accuracy: 0.9350\n",
            "Epoch 00021: val_loss did not improve from 0.27836\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1895 - accuracy: 0.9350 - val_loss: 0.3494 - val_accuracy: 0.8957\n",
            "Epoch 22/100\n",
            "1399/1407 [============================>.] - ETA: 0s - loss: 0.1896 - accuracy: 0.9359\n",
            "Epoch 00022: val_loss did not improve from 0.27836\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1899 - accuracy: 0.9359 - val_loss: 0.2921 - val_accuracy: 0.9115\n",
            "Epoch 23/100\n",
            "1402/1407 [============================>.] - ETA: 0s - loss: 0.1814 - accuracy: 0.9386\n",
            "Epoch 00023: val_loss improved from 0.27836 to 0.27189, saving model to /content/drive/My Drive/models/amazon_bert.h5\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1816 - accuracy: 0.9386 - val_loss: 0.2719 - val_accuracy: 0.9168\n",
            "Epoch 24/100\n",
            "1398/1407 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9394\n",
            "Epoch 00024: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1779 - accuracy: 0.9395 - val_loss: 0.3054 - val_accuracy: 0.9091\n",
            "Epoch 25/100\n",
            "1394/1407 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 0.9410\n",
            "Epoch 00025: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1746 - accuracy: 0.9411 - val_loss: 0.2880 - val_accuracy: 0.9141\n",
            "Epoch 26/100\n",
            "1401/1407 [============================>.] - ETA: 0s - loss: 0.1728 - accuracy: 0.9408\n",
            "Epoch 00026: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1732 - accuracy: 0.9406 - val_loss: 0.2983 - val_accuracy: 0.9115\n",
            "Epoch 27/100\n",
            "1399/1407 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9434\n",
            "Epoch 00027: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1664 - accuracy: 0.9434 - val_loss: 0.3344 - val_accuracy: 0.9034\n",
            "Epoch 28/100\n",
            "1397/1407 [============================>.] - ETA: 0s - loss: 0.1640 - accuracy: 0.9435\n",
            "Epoch 00028: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1640 - accuracy: 0.9436 - val_loss: 0.3001 - val_accuracy: 0.9092\n",
            "Epoch 29/100\n",
            "1403/1407 [============================>.] - ETA: 0s - loss: 0.1604 - accuracy: 0.9445\n",
            "Epoch 00029: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1602 - accuracy: 0.9446 - val_loss: 0.3287 - val_accuracy: 0.9078\n",
            "Epoch 30/100\n",
            "1395/1407 [============================>.] - ETA: 0s - loss: 0.1572 - accuracy: 0.9457\n",
            "Epoch 00030: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1569 - accuracy: 0.9458 - val_loss: 0.3463 - val_accuracy: 0.8986\n",
            "Epoch 31/100\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 0.1528 - accuracy: 0.9470\n",
            "Epoch 00031: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1528 - accuracy: 0.9470 - val_loss: 0.3142 - val_accuracy: 0.9114\n",
            "Epoch 32/100\n",
            "1397/1407 [============================>.] - ETA: 0s - loss: 0.1477 - accuracy: 0.9485\n",
            "Epoch 00032: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1479 - accuracy: 0.9485 - val_loss: 0.3052 - val_accuracy: 0.9114\n",
            "Epoch 33/100\n",
            "1392/1407 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9498\n",
            "Epoch 00033: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1436 - accuracy: 0.9497 - val_loss: 0.3655 - val_accuracy: 0.8974\n",
            "Epoch 34/100\n",
            "1392/1407 [============================>.] - ETA: 0s - loss: 0.1426 - accuracy: 0.9508\n",
            "Epoch 00034: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1424 - accuracy: 0.9509 - val_loss: 0.3280 - val_accuracy: 0.9077\n",
            "Epoch 35/100\n",
            "1396/1407 [============================>.] - ETA: 0s - loss: 0.1396 - accuracy: 0.9519\n",
            "Epoch 00035: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1396 - accuracy: 0.9518 - val_loss: 0.3580 - val_accuracy: 0.9048\n",
            "Epoch 36/100\n",
            "1396/1407 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.9527\n",
            "Epoch 00036: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1361 - accuracy: 0.9528 - val_loss: 0.3366 - val_accuracy: 0.9078\n",
            "Epoch 37/100\n",
            "1396/1407 [============================>.] - ETA: 0s - loss: 0.1319 - accuracy: 0.9543\n",
            "Epoch 00037: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1320 - accuracy: 0.9543 - val_loss: 0.3130 - val_accuracy: 0.9125\n",
            "Epoch 38/100\n",
            "1396/1407 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9554\n",
            "Epoch 00038: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1286 - accuracy: 0.9554 - val_loss: 0.3569 - val_accuracy: 0.9007\n",
            "Epoch 39/100\n",
            "1395/1407 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 0.9556\n",
            "Epoch 00039: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1287 - accuracy: 0.9556 - val_loss: 0.3387 - val_accuracy: 0.9063\n",
            "Epoch 40/100\n",
            "1401/1407 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.9556\n",
            "Epoch 00040: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1260 - accuracy: 0.9557 - val_loss: 0.3545 - val_accuracy: 0.9008\n",
            "Epoch 41/100\n",
            "1401/1407 [============================>.] - ETA: 0s - loss: 0.1185 - accuracy: 0.9595\n",
            "Epoch 00041: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1187 - accuracy: 0.9595 - val_loss: 0.3456 - val_accuracy: 0.9105\n",
            "Epoch 42/100\n",
            "1404/1407 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.9582\n",
            "Epoch 00042: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1177 - accuracy: 0.9582 - val_loss: 0.3544 - val_accuracy: 0.9091\n",
            "Epoch 43/100\n",
            "1398/1407 [============================>.] - ETA: 0s - loss: 0.1173 - accuracy: 0.9587Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.27189\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1175 - accuracy: 0.9586 - val_loss: 0.3371 - val_accuracy: 0.9145\n",
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb9f049c438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_nfJCH5HOzv"
      },
      "source": [
        "## Evaluating Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swLVI2Ec8QeU"
      },
      "source": [
        "y_hat = model.predict(X_val)\n",
        "y_hat = np.argmax(y_hat, axis=1)"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXN6JMUh8ZlB"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "  \"\"\"\n",
        "  This function prints and plots the confusion matrix.\n",
        "  Normalization can be applied by setting `normalize=True`.\n",
        "  \"\"\"\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "      print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "      print('Confusion matrix, without normalization')\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], fmt),\n",
        "               horizontalalignment=\"center\",\n",
        "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6WSbxYH8dLY",
        "outputId": "65ab297b-5562-41ab-ab75-1d68dc3d0dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "cm = confusion_matrix(y_val, y_hat)\n",
        "plot_confusion_matrix(cm, [0,1,2,3,4,5])"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[2072    2   25   19   69   10]\n",
            " [   8  191    1    6   20    5]\n",
            " [  19    0  562    7   20   47]\n",
            " [  23    1    3  963   47   12]\n",
            " [  96   10   25   46 2891   40]\n",
            " [   8    3   35   25   29  602]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}