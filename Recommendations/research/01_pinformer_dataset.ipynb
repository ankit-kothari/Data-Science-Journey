{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install openai\n",
    "#!pip3 install scikit-learn\n",
    "#!pip3 install matplotlib\n",
    "#!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "gradio_client\n",
    "langchain\n",
    "openai\n",
    "pydub\n",
    "Pillow\n",
    "tiktoken\n",
    "unstructured[local-inference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankitkothari/Library/Python/3.9/lib/python/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import openai\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import transformers\n",
    "import ast\n",
    "import pprint\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import plotly.express as px\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from getpass import getpass\n",
    "from gradio_client import Client\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "from time import sleep\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "conversation_topics = [\n",
    "    \"Artificial Intelligence and its impact on society\",\n",
    "    \"Space exploration and the future of interplanetary travel\",\n",
    "    \"Climate change and its effects on the environment\",\n",
    "    \"Ethical considerations of gene editing and genetic engineering\",\n",
    "    \"The rise of renewable energy and its impact on fossil fuels\",\n",
    "    \"The future of work in the age of automation and AI\",\n",
    "    \"The role of social media in shaping public opinion\",\n",
    "    \"Challenges and benefits of globalization\",\n",
    "    \"The impact of technology on mental health\",\n",
    "    \"Exploring the mysteries of the universe and dark matter\",\n",
    "    \"The future of education and online learning\",\n",
    "    \"The ethics of artificial intelligence and robotics\",\n",
    "    \"The impact of social media on interpersonal relationships\",\n",
    "    \"Cultural diversity and its significance in a globalized world\",\n",
    "    \"The role of governments in addressing income inequality\",\n",
    "    \"The rise of virtual reality and its applications\",\n",
    "    \"The effects of automation on job displacement\",\n",
    "    \"The future of healthcare and medical advancements\",\n",
    "    \"The importance of data privacy and digital security\",\n",
    "    \"The challenges and potential of renewable energy sources\",\n",
    "    \"Exploring the possibilities of quantum computing\",\n",
    "    \"The influence of mass media on society and politics\",\n",
    "    \"The ethical implications of autonomous vehicles\",\n",
    "    \"The future of cryptocurrency and blockchain technology\",\n",
    "    \"The impact of climate change on wildlife and ecosystems\",\n",
    "    \"The role of artificial intelligence in art and creativity\",\n",
    "    \"Challenges and opportunities in sustainable agriculture\",\n",
    "    \"The rise of biotechnology and its implications\",\n",
    "    \"The future of space tourism and colonization\",\n",
    "    \"The impact of virtual currencies on global economics\",\n",
    "    \"The effects of social media on mental health\",\n",
    "    \"The significance of cultural preservation and heritage\",\n",
    "    \"The challenges of overpopulation and urbanization\",\n",
    "    \"The role of AI in improving healthcare diagnostics\",\n",
    "    \"The impact of automation on the manufacturing industry\",\n",
    "    \"The future of transportation and autonomous vehicles\",\n",
    "    \"The ethical considerations of human augmentation\",\n",
    "    \"The rise of smart cities and urban planning\",\n",
    "    \"The effects of climate change on agriculture and food security\",\n",
    "    \"The influence of technology on the entertainment industry\",\n",
    "    \"The potential of renewable energy in developing nations\",\n",
    "    \"The implications of artificial intelligence in warfare\",\n",
    "    \"The future of space exploration and potential life on other planets\",\n",
    "    \"The impact of social media on political movements\",\n",
    "    \"The challenges and benefits of 5G technology\",\n",
    "    \"The role of AI in personalized medicine\",\n",
    "    \"The ethical dilemmas of human cloning\",\n",
    "    \"The future of virtual reality in various fields\",\n",
    "    \"The impact of automation on income distribution\",\n",
    "    \"The possibilities and limitations of nanotechnology\",\n",
    "]\n",
    "\n",
    "# Check the total number of topics in the list\n",
    "print(len(conversation_topics)) # Output: 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_topics = [\n",
    "    \"Challenges and opportunities in Indian politics\",\n",
    "    \"Celebrating the diversity of cultures in India\",\n",
    "    \"Exploring the rich artistic talent in India\",\n",
    "    \"The impact of Indian cinema on the global stage\",\n",
    "    \"The role of women in Indian politics and society\",\n",
    "    \"Preserving traditional Indian art forms in the modern world\",\n",
    "    \"The influence of Indian cuisine on international food trends\",\n",
    "    \"The rise of Indian technology startups and innovation\",\n",
    "    \"The future of renewable energy in India\",\n",
    "    \"Addressing environmental challenges in Indian cities\",\n",
    "    \"Understanding the complexities of India's education system\",\n",
    "    \"Analyzing the US economy and its global implications\",\n",
    "    \"The entrepreneurial journey of Elon Musk and his ventures\",\n",
    "    \"Space exploration and the vision of SpaceX\",\n",
    "    \"Tesla's impact on the automotive industry and sustainability\",\n",
    "    \"Neuralink and the potential of brain-computer interfaces\",\n",
    "    \"The debate between long-form threads and Twitter's character limit\",\n",
    "    \"Twitter's role in shaping public discourse and political movements\",\n",
    "    \"The impact of social media on global communication\",\n",
    "    \"Promoting civil discourse and combating misinformation online\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"OPENAI_API_KEY\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_facts = []\n",
    "for topic in conversation_topics:\n",
    "  system_prompt = f\"You are a journalist whose job is to research and write about a varierty of topics\"\n",
    "\n",
    "  prompt =  f\"\"\" Please  use the following topic \"{topic}\" and write 20 most interestng and diverse facts about it.  \\\n",
    "             Return the output as a python dictionary with the following format and it should not be a string:\n",
    "  \n",
    "   \n",
    "   topic: One word summary of {topic} example \"AI\"\n",
    "   facts: 20 facts about the topic in a list format example: [\"fact 1\", \"fact 2\", \"fact 3\", \"fact 4\", \"fact 5\", \"fact 6\", \"fact 7\", \"fact 8\", \"fact 9\", \"fact 10\", \"fact 11\", \"fact 12\", \"fact 13\", \"fact 14\", \"fact 15\", \"fact 16\", \"fact 17\", \"fact 18\", \"fact 19\", \"fact 20\"]\n",
    "   \n",
    " \"\"\"\n",
    "        # Generate response\n",
    "  messages=[{'role': 'system', 'content': f\"{system_prompt}\"}, {'role': 'user', 'content': f\"{prompt}\"}]\n",
    "  #messages = messages=[{'role': 'system', 'content': 'You are a helpful tour guide.'}, {'role': 'user', 'content': 'What is the first US state?'}]\n",
    "  response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=messages)\n",
    "  response_as_dict =response['choices'][0][\"message\"][\"content\"]\n",
    "  topic_facts.append(response_as_dict)\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Politics',\n",
       " 'facts': [\"India is the world's largest democracy.\",\n",
       "  'Indian politics is characterized by a multi-party system, with the most prominent parties being the Indian National Congress and the Bharatiya Janata Party.',\n",
       "  'The President of India is the ceremonial head of state, while the Prime Minister holds the executive power.',\n",
       "  'One of the biggest challenges in Indian politics is corruption, with many politicians being involved in bribery and embezzlement.',\n",
       "  'Indian politics is often criticized for its dynastic politics, with many political leaders coming from powerful political families.',\n",
       "  \"Another challenge is the lack of women's representation in politics, with only around 14% of seats in the Lok Sabha (lower house of parliament) being occupied by women.\",\n",
       "  'Caste-based politics is a significant factor in Indian politics, with different political parties vying for the support of specific caste groups.',\n",
       "  'Regionalism is another challenge, with regional parties having significant influence in certain states and often demanding greater autonomy for their respective regions.',\n",
       "  'Religious tensions and communal violence have also been a major challenge in Indian politics, with some political parties accused of using religious divides for political gain.',\n",
       "  'Indian politics is known for its vibrant and lively election campaigns, with millions of people participating in the electoral process.',\n",
       "  'India has had several prominent women politicians, including Indira Gandhi, the first and only female Prime Minister of India.',\n",
       "  'The introduction of the Aadhaar card, a unique identification system, is seen as a positive step towards combating corruption in Indian politics.',\n",
       "  'The rise of social media has significantly influenced Indian politics, with political leaders actively using platforms like Twitter and Facebook to connect with voters.',\n",
       "  'One of the opportunities in Indian politics is the potential for economic growth and development, which can lead to improved living standards for the population.',\n",
       "  'Another opportunity is the increasing participation of young people in politics, who bring fresh ideas and perspectives to the table.',\n",
       "  'Digitalization of government services and processes has the potential to make the political system more transparent and efficient.',\n",
       "  'The empowerment of marginalized communities, such as Dalits and tribal groups, is also an opportunity in Indian politics.',\n",
       "  \"India's growing influence on the global stage provides an opportunity for the country to play a significant role in global politics and diplomacy.\",\n",
       "  'The presence of a diverse and multicultural society in India is an opportunity to promote inclusivity and diversity in politics.',\n",
       "  'The decentralization of power to local governments can lead to better governance and accountability.']}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_facts[0]\n",
    "ast.literal_eval(topic_facts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "topic_fact = {}\n",
    "for response_as_dict in topic_facts:\n",
    "    try: \n",
    "      responses = ast.literal_eval(response_as_dict)\n",
    "      topic = responses[\"topic\"]\n",
    "      topic_fact[topic] =responses[\"facts\"][0:20]\n",
    "    except:\n",
    "        print(\"error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politics 20\n",
      "Diversity in India 20\n",
      "Art 20\n",
      "Indian cinema 20\n",
      "Women in Indian politics 20\n",
      "Traditional Indian Art 20\n",
      "Indian_cuisine 20\n",
      "IndianTech 20\n",
      "Renewable Energy 20\n",
      "Environmental Challenges in Indian Cities 20\n",
      "US Economy 20\n",
      "The entrepreneurial journey of Elon Musk and his ventures 20\n",
      "Tesla's Impact 20\n",
      "Long-form vs Twitter's character limit debate 20\n",
      "Twitter 20\n",
      "socialmedia 20\n",
      "discourse 20\n"
     ]
    }
   ],
   "source": [
    "new_dict = {}\n",
    "for key, value in topic_fact.items():\n",
    "    print(key, len(value))\n",
    "    #if len(value) != 20:\n",
    "    # del topic_fact[key]\n",
    "    if len(value) == 20:\n",
    "        new_dict[key] = value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Politics</td>\n",
       "      <td>India is the world's largest democracy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Indian politics is characterized by a multi-pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politics</td>\n",
       "      <td>The President of India is the ceremonial head ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politics</td>\n",
       "      <td>One of the biggest challenges in Indian politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Indian politics is often criticized for its dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>discourse</td>\n",
       "      <td>Journalists and media organizations have a res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>discourse</td>\n",
       "      <td>Promoting transparency in algorithms and conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>discourse</td>\n",
       "      <td>Developing critical thinking skills is crucial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>discourse</td>\n",
       "      <td>Online harassment and hate speech can hinder c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>discourse</td>\n",
       "      <td>Collaboration between tech companies, research...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic                                               fact\n",
       "0     Politics            India is the world's largest democracy.\n",
       "1     Politics  Indian politics is characterized by a multi-pa...\n",
       "2     Politics  The President of India is the ceremonial head ...\n",
       "3     Politics  One of the biggest challenges in Indian politi...\n",
       "4     Politics  Indian politics is often criticized for its dy...\n",
       "..         ...                                                ...\n",
       "335  discourse  Journalists and media organizations have a res...\n",
       "336  discourse  Promoting transparency in algorithms and conte...\n",
       "337  discourse  Developing critical thinking skills is crucial...\n",
       "338  discourse  Online harassment and hate speech can hinder c...\n",
       "339  discourse  Collaboration between tech companies, research...\n",
       "\n",
       "[340 rows x 2 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#polars dataframe from dictionary\n",
    "df = pd.DataFrame.from_dict(new_dict, orient=\"columns\")\n",
    "\n",
    "new_df = pd.DataFrame( columns=['topic', 'fact'])\n",
    "for col in df.columns:\n",
    "    temp_df= pd.DataFrame(columns=['topic', 'fact'])\n",
    "    temp_df.loc[:,\"fact\"] = df.loc[:,col]\n",
    "    temp_df.loc[:,\"topic\"] = col\n",
    "    new_df = pd.concat([new_df, temp_df], ignore_index=True)\n",
    "new_df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe to csv\n",
    "new_df.to_csv(\"topic_facts_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"topic_facts_2.csv\")\n",
    "df2 = pd.read_csv(\"topic_facts_1.csv\")\n",
    "df3 = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "#sample 1000 rows and reset index\n",
    "df4 = df3.sample(n=1000, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.reset_index()\n",
    "df4 = df4.rename(columns={\"index\": \"pin_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()\n",
    "#save dataframe to csv\n",
    "df4['topic'] = df4['topic'].str.replace('_', ' ')\n",
    "df4['topic'] = df4['topic'].str.replace('climatechange', 'climate change')\n",
    "df4['topic'] = df4['topic'].str.replace('vr', 'virtual reality')\n",
    "df4['topic'] = df4['topic'].str.lower()\n",
    "df4.to_csv(\"topic_facts_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pin_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>renewable energy</td>\n",
       "      <td>Renewable energy can improve access to clean c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>media</td>\n",
       "      <td>Media can amplify the voices of marginalized g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>socialmedia</td>\n",
       "      <td>The anonymity of social media can sometimes le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>indian cuisine</td>\n",
       "      <td>Indian cuisine is characterized by its wide ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cultural diversity</td>\n",
       "      <td>It emphasizes the importance of cultural prese...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pin_id               topic  \\\n",
       "0       0    renewable energy   \n",
       "1       1               media   \n",
       "2       2         socialmedia   \n",
       "3       3      indian cuisine   \n",
       "4       4  cultural diversity   \n",
       "\n",
       "                                                fact  \n",
       "0  Renewable energy can improve access to clean c...  \n",
       "1  Media can amplify the voices of marginalized g...  \n",
       "2  The anonymity of social media can sometimes le...  \n",
       "3  Indian cuisine is characterized by its wide ra...  \n",
       "4  It emphasizes the importance of cultural prese...  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pin_id</th>\n",
       "      <th>fact</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5g</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automation</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autonomous vehicles</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>autonomous-vehicles</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climate change</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climatechange</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cryptocurrency</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cultural diversity</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cultural preservation</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data privacy and digital security</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discourse</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diversity in india</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>environmental challenges in indian cities</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethical cloning</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethics</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>future of education</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>futureofwork</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene editing</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>globalization</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>government</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian cinema</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian cuisine</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indiantech</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long-form vs twitter's character limit debate</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>media</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nanotechnology</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overpopulation and urbanization</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantum</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renewable energy</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smart cities</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social media</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social media and mental health</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socialmedia</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socialmedia-impact</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space exploration</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space tourism</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sustainable agriculture</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tesla's impact</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the entrepreneurial journey of elon musk and his ventures</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the future of healthcare and medical advancements</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traditional indian art</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>universe</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us economy</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virtual currencies</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vr</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women in indian politics</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    pin_id  fact\n",
       "topic                                                           \n",
       "5g                                                      19    19\n",
       "ai                                                      19    19\n",
       "art                                                     19    19\n",
       "automation                                              19    19\n",
       "autonomous vehicles                                     18    18\n",
       "autonomous-vehicles                                     20    20\n",
       "climate change                                          38    38\n",
       "climatechange                                           18    18\n",
       "cryptocurrency                                          19    19\n",
       "cultural diversity                                      20    20\n",
       "cultural preservation                                   17    17\n",
       "data privacy and digital security                       18    18\n",
       "discourse                                               19    19\n",
       "diversity in india                                      19    19\n",
       "environmental challenges in indian cities               19    19\n",
       "ethical cloning                                         18    18\n",
       "ethics                                                  17    17\n",
       "future of education                                     18    18\n",
       "futureofwork                                            18    18\n",
       "gene editing                                            20    20\n",
       "globalization                                           19    19\n",
       "government                                              17    17\n",
       "indian cinema                                           18    18\n",
       "indian cuisine                                          19    19\n",
       "indiantech                                              16    16\n",
       "long-form vs twitter's character limit debate           19    19\n",
       "media                                                   16    16\n",
       "nanotechnology                                          18    18\n",
       "overpopulation and urbanization                         18    18\n",
       "politics                                                19    19\n",
       "quantum                                                 19    19\n",
       "renewable energy                                        39    39\n",
       "smart cities                                            18    18\n",
       "social media                                            19    19\n",
       "social media and mental health                          18    18\n",
       "socialmedia                                             34    34\n",
       "socialmedia-impact                                      16    16\n",
       "space exploration                                       20    20\n",
       "space tourism                                           19    19\n",
       "sustainable agriculture                                 19    19\n",
       "technology                                              16    16\n",
       "tesla's impact                                          18    18\n",
       "the entrepreneurial journey of elon musk and hi...      19    19\n",
       "the future of healthcare and medical advancements       19    19\n",
       "traditional indian art                                  20    20\n",
       "twitter                                                 20    20\n",
       "universe                                                19    19\n",
       "us economy                                              19    19\n",
       "virtual currencies                                      19    19\n",
       "vr                                                      19    19\n",
       "women in indian politics                                20    20"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.groupby('topic').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting pin embeddings using Huggingface transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df4 = pd.read_csv(\"topic_facts_3.csv\")\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 17:34:40.304186: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/ankitkothari/Library/Python/3.9/lib/python/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline,  AutoModelForTokenClassification, AutoTokenizer, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import AutoConfig, EarlyStoppingCallback, TrainerCallback\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization import quantize_dynamic, QuantStub, DeQuantStub\n",
    "class product_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, checkpoint, max_len):\n",
    "        self.topic  = df.topic \n",
    "        self.fact = df.fact\n",
    "        self.pin_id = df.pin_id\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        self.tokenizer.add_special_tokens = {\"additional_special_tokens\": [\"[TOPIC]\", \"[FACT]\"], \"pad_token\": \"[PAD]\"}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.topic)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        topic = self.topic[idx]\n",
    "        fact = self.fact[idx]\n",
    "        compined_prompt = f\"[TOPIC] {topic} [FACT] {fact}\"\n",
    "        tokenize_facts = self.tokenizer(compined_prompt, padding=\"max_length\", \n",
    "                                            truncation=True,\n",
    "                                             max_length=self.max_len,\n",
    "                                             return_tensors=\"pt\",\n",
    "                                             add_special_tokens=True,\n",
    "                                             return_attention_mask=True\n",
    "                                                )\n",
    "                                                \n",
    "        \n",
    "        item = {\"input_ids\": tokenize_facts[\"input_ids\"].flatten(),\n",
    "                \"toke_type_ids\": tokenize_facts[\"token_type_ids\"].flatten(),\n",
    "                \"attention_mask\": tokenize_facts[\"attention_mask\"].flatten()}                                \n",
    "\n",
    "        return item\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class product_embedding_model(nn.Module):\n",
    "    def __init__(self , checkpoint, config, quantization_config=None):\n",
    "        super(product_embedding_model, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(checkpoint, config=config, quantization_config=quantization_config)\n",
    "        self.quantized_model = quantize_dynamic(self.model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, device):\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        model_output =  self.quantized_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        with torch.no_grad():\n",
    "            last_hidden_state = model_output.last_hidden_state\n",
    "            mean_pooling = torch.mean(last_hidden_state, 1)\n",
    "            #layer normalization of mean_pooling\n",
    "            normalized_embeddings = nn.LayerNorm(mean_pooling.size())(mean_pooling)\n",
    "        return normalized_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = product_embedding_model(\"sentence-transformers/paraphrase-MiniLM-L6-v2\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190a44a140b84ed9abc1d1819b9badc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "dataset = product_dataset(df4, \"sentence-transformers/paraphrase-MiniLM-L6-v2\", 128)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "embeddings = []\n",
    "for batch in tqdm_notebook(dataloader):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    token_type_ids = batch[\"toke_type_ids\"]\n",
    "    batch_embeddings = model(input_ids, attention_mask, token_type_ids, device)\n",
    "    embeddings.append(batch_embeddings)\n",
    "\n",
    "embeddings = torch.cat(embeddings, dim=0)\n",
    "#save embeddings to pickle file\n",
    "pickle.dump(embeddings, open(\"embeddings.pkl\", \"wb\"))\n",
    "\n",
    "#load embeddings from pickle file\n",
    "embeddings = pickle.load(open(\"embeddings.pkl\", \"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 384])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = product_dataset(df4.iloc[0], \"sentence-transformers/paraphrase-MiniLM-L6-v2\", 6)\n",
    "#sample_loader = DataLoader(sample, batch_size=1, shuffle=False)\n",
    "#for batch in sample_loader:\n",
    "#    print(batch[\"input_ids\"].shape)\n",
    "#    print(batch[\"attention_mask\"].shape)\n",
    "#    break\n",
    "#for batch in sample_loader:\n",
    "#    embeddings = model(batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"toke_type_ids\"], device)\n",
    "#embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 384)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embeddings.cpu().numpy()\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of embeddings in bytes\n",
    "embeddings.nbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a90b5e8f8943f6a0992fe4a24748d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64d3a822ec04a6e9a6584a5ce469c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e492f32427a84c9ebef34fc32023466e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0d4a69d5074e2184d819035c70f28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef17f6231c3647b7a5eebf8727048efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1649,  0.2098,  0.1385,  ..., -0.2731,  0.1301,  0.5502],\n",
      "         [-0.5741, -0.0484,  0.2628,  ..., -0.4065,  0.0185,  0.1929],\n",
      "         [ 0.0911, -0.3613,  0.3993,  ..., -0.0039, -0.0625,  0.7234],\n",
      "         ...,\n",
      "         [-0.0804,  0.2757,  0.7342,  ..., -0.2625,  0.2136,  0.7162],\n",
      "         [-0.0145,  0.7296, -0.2356,  ..., -0.3143, -0.1940,  0.1607],\n",
      "         [ 0.1101,  0.1383, -0.3145,  ...,  1.0134, -0.6452, -0.1105]]]), pooler_output=tensor([[-7.1793e-01, -1.4331e-01,  6.1747e-01,  3.8488e-01, -2.1553e-01,\n",
      "         -5.8050e-02,  6.7497e-01,  7.0395e-02,  5.1126e-01, -9.9917e-01,\n",
      "          3.4123e-01, -7.0138e-02,  9.5945e-01, -6.2450e-01,  7.5708e-01,\n",
      "         -2.8040e-01,  1.8364e-01, -3.7239e-01,  1.5166e-01, -3.3933e-01,\n",
      "          3.5367e-01,  8.5352e-01,  7.2095e-01,  1.0507e-01,  1.7852e-01,\n",
      "         -2.6012e-01, -3.2006e-01,  8.6234e-01,  8.9268e-01,  6.4441e-01,\n",
      "         -4.9987e-01,  1.6331e-01, -9.6879e-01, -4.0247e-02,  3.6979e-01,\n",
      "         -9.4514e-01,  7.0516e-02, -6.1300e-01,  1.5716e-01,  2.6500e-02,\n",
      "         -7.8961e-01,  1.9933e-01,  9.8904e-01, -3.8741e-01, -8.5729e-02,\n",
      "         -2.1762e-01, -9.9051e-01,  6.8205e-02, -7.8518e-01, -6.1067e-01,\n",
      "         -4.8493e-01, -6.2545e-01,  2.5470e-02,  1.5845e-01,  2.5114e-01,\n",
      "          4.4077e-01, -2.5750e-01,  8.7022e-02,  2.9572e-02, -3.7716e-01,\n",
      "         -3.6904e-01,  2.1132e-01,  3.0134e-01, -7.8108e-01, -5.1482e-01,\n",
      "         -7.1457e-01,  5.8702e-02, -1.2963e-01,  1.1006e-01, -1.2774e-01,\n",
      "          6.4913e-01,  5.2056e-02,  3.6947e-01, -6.7673e-01, -5.5933e-01,\n",
      "          2.2453e-02, -3.1909e-01,  9.9956e-01, -1.4058e-01, -9.4760e-01,\n",
      "         -4.0400e-01, -5.4721e-01,  1.8248e-01,  7.8608e-01, -7.1863e-01,\n",
      "         -9.9823e-01,  1.2664e-01, -5.1579e-02, -9.7287e-01, -4.1237e-02,\n",
      "          1.9440e-01,  3.2950e-02, -6.3379e-01,  2.2480e-01,  2.0209e-01,\n",
      "         -2.2745e-02, -2.7414e-02,  4.0354e-01, -3.9164e-02,  3.8074e-02,\n",
      "         -4.0856e-02, -5.1463e-02,  1.6123e-01, -1.7071e-01,  3.9757e-02,\n",
      "         -1.2620e-01, -1.7972e-01, -7.3020e-03, -5.2171e-01,  4.5049e-01,\n",
      "          2.0947e-01, -8.2556e-02,  2.1657e-02, -8.8025e-01,  4.0412e-01,\n",
      "         -1.1361e-01, -9.6028e-01, -2.4743e-01, -9.6732e-01,  5.0401e-01,\n",
      "          2.3074e-01,  2.3621e-02,  8.7119e-01,  6.9340e-01,  1.3004e-01,\n",
      "          1.5576e-01,  4.3711e-01, -9.9984e-01, -7.3080e-02, -1.3571e-01,\n",
      "          4.4367e-01,  4.5938e-02, -9.5446e-01, -9.1205e-01,  4.1524e-01,\n",
      "          9.1665e-01,  1.3701e-02,  9.8248e-01,  4.6681e-02,  8.5453e-01,\n",
      "          5.4809e-01,  1.1490e-01, -5.8642e-01, -1.5315e-01,  2.1665e-01,\n",
      "          1.5505e-01, -5.4419e-01, -9.7158e-03,  1.9654e-01, -2.5461e-01,\n",
      "          3.1838e-02, -1.1877e-01,  5.0738e-01, -8.3898e-01, -2.6856e-01,\n",
      "          8.5719e-01,  3.8330e-01,  6.7569e-01,  8.0528e-01, -2.0890e-02,\n",
      "         -1.4585e-01,  6.8779e-01,  1.8851e-01,  9.7172e-02,  3.1404e-01,\n",
      "          2.1631e-01, -5.0249e-01,  2.7989e-01, -7.7953e-01,  4.3697e-01,\n",
      "          1.8459e-01, -2.0611e-02,  4.8799e-01, -9.5077e-01, -2.1291e-02,\n",
      "          3.3482e-01,  9.6543e-01,  6.4148e-01,  1.0083e-01, -2.5333e-01,\n",
      "         -1.6330e-01, -1.4788e-02, -8.8309e-01,  9.4836e-01,  3.4578e-02,\n",
      "          1.1586e-01,  5.1103e-01, -3.4286e-01, -7.0600e-01, -6.0616e-01,\n",
      "          6.4768e-01,  1.7188e-01, -7.6937e-01,  1.4954e-01, -3.1658e-01,\n",
      "         -1.8462e-01,  2.2984e-01,  4.3053e-01, -7.8495e-02, -2.2356e-01,\n",
      "          1.0068e-01,  8.5406e-01,  8.2856e-01,  5.2555e-01, -5.7443e-01,\n",
      "          3.3461e-01, -7.2358e-01, -1.5181e-01, -3.9424e-02,  8.8301e-02,\n",
      "         -1.1791e-01,  9.7472e-01,  1.0624e-02, -2.9769e-02, -8.0153e-01,\n",
      "         -9.5045e-01, -1.1823e-01, -7.4653e-01,  1.0562e-01, -5.1286e-01,\n",
      "          9.7536e-03,  5.4494e-01, -5.1463e-01,  1.3280e-01, -8.8614e-01,\n",
      "         -6.3545e-01,  1.3826e-01, -1.0887e-01,  2.2614e-01, -6.6214e-02,\n",
      "          6.2028e-01, -3.7425e-01, -4.1937e-01,  3.3303e-01,  8.4729e-01,\n",
      "          5.9366e-01, -5.8947e-01,  5.2534e-01, -6.3571e-02,  7.8787e-01,\n",
      "         -3.3362e-01,  9.2131e-01, -1.9190e-01,  7.9548e-02, -8.2554e-01,\n",
      "          5.5633e-01, -7.2497e-01,  5.8455e-01, -2.6544e-02, -8.0021e-01,\n",
      "         -5.7977e-01,  2.6120e-01,  7.8372e-02,  8.6841e-01, -3.0550e-01,\n",
      "          9.2175e-01, -4.8307e-01, -9.0681e-01, -1.2408e-01,  3.7198e-01,\n",
      "         -9.6421e-01, -2.4671e-01,  7.4035e-02, -3.9143e-01, -1.8357e-01,\n",
      "         -2.1055e-01, -8.9621e-01,  7.1497e-01, -2.3233e-03,  9.3004e-01,\n",
      "          2.3644e-01, -6.8420e-01, -3.7214e-02, -8.0989e-01, -2.6913e-01,\n",
      "          3.4036e-02,  7.5972e-01, -2.3976e-01, -8.5558e-01,  2.7195e-01,\n",
      "          4.1882e-01,  1.6148e-01,  7.1833e-01,  9.4141e-01,  9.8750e-01,\n",
      "          9.4086e-01,  7.2393e-01,  6.2004e-01, -7.3018e-01, -2.3782e-01,\n",
      "          9.9948e-01, -1.0617e-01, -9.9755e-01, -8.7023e-01, -2.7425e-01,\n",
      "          2.4878e-01, -9.9975e-01, -3.5874e-02,  1.5473e-01, -7.8814e-01,\n",
      "         -6.0440e-01,  9.4998e-01,  8.6970e-01, -9.9954e-01,  7.7990e-01,\n",
      "          8.6780e-01, -2.8404e-01, -2.0897e-01, -1.1398e-02,  9.4106e-01,\n",
      "         -3.9068e-04,  3.8655e-01,  7.3939e-02,  1.3347e-01,  3.1944e-01,\n",
      "         -6.6873e-01,  4.9965e-01,  5.8208e-01,  3.6256e-01, -4.3706e-02,\n",
      "         -5.7426e-01, -7.9526e-01, -1.8491e-01,  1.4169e-01, -4.0753e-01,\n",
      "         -9.0560e-01, -1.6379e-03, -5.2681e-01,  3.5172e-01,  4.6103e-02,\n",
      "          9.5779e-02, -6.0721e-01,  9.0910e-02, -7.6605e-01,  1.1119e-01,\n",
      "          3.0703e-01, -8.3954e-01, -3.2720e-01, -1.9305e-02, -5.4429e-01,\n",
      "          5.7981e-01, -9.3220e-01,  9.0697e-01, -4.4788e-02, -2.0085e-01,\n",
      "          9.9964e-01, -9.4784e-02, -6.6603e-01,  1.3917e-01, -2.3521e-02,\n",
      "         -2.2855e-01,  9.9900e-01,  9.9454e-02, -9.5332e-01, -1.8943e-01,\n",
      "         -6.5573e-02, -1.3191e-01, -1.0720e-01,  9.9062e-01,  1.1719e-02,\n",
      "          5.4383e-01,  4.6435e-01,  9.5083e-01, -9.7516e-01,  3.5774e-02,\n",
      "         -7.7764e-01, -9.1026e-01,  8.9160e-01,  8.4457e-01,  8.4920e-02,\n",
      "         -5.3465e-01, -7.8056e-02,  4.1745e-01,  6.6710e-02, -8.4276e-01,\n",
      "          2.7323e-01,  2.0163e-01,  1.2783e-01,  7.6754e-01, -5.9836e-01,\n",
      "         -2.8181e-01,  2.5533e-01,  2.9267e-01,  4.7194e-01, -3.2899e-01,\n",
      "          2.6482e-01, -9.3818e-02, -8.0316e-02, -3.2095e-02, -2.1393e-01,\n",
      "         -9.2790e-01, -8.3671e-02,  9.9918e-01,  2.6388e-01, -4.9622e-01,\n",
      "          2.6438e-01,  6.6658e-02, -3.7712e-01,  2.1045e-01,  2.2663e-01,\n",
      "         -7.0013e-02, -6.3278e-01, -3.6420e-01, -6.2070e-01, -9.7112e-01,\n",
      "          4.4957e-01,  2.9189e-02, -1.5738e-01,  9.6610e-01, -5.8282e-02,\n",
      "         -1.8243e-02, -2.4778e-01, -2.3945e-01, -6.4306e-02,  1.8244e-01,\n",
      "         -7.6334e-01,  9.4093e-01, -1.3157e-01,  2.3179e-01,  5.6953e-01,\n",
      "          6.7203e-01, -1.7614e-01, -4.6527e-01, -9.8575e-02, -8.8190e-01,\n",
      "          9.8065e-02, -8.7318e-01,  9.1502e-01, -5.5794e-01,  7.9359e-02,\n",
      "         -8.9008e-02, -1.8623e-01,  9.9957e-01, -3.0811e-01,  4.4946e-01,\n",
      "         -3.9396e-02,  5.3001e-01, -6.6795e-01, -4.4078e-01, -1.6664e-01,\n",
      "          1.3245e-01,  7.2874e-01, -7.2536e-02, -3.6344e-03, -9.3164e-01,\n",
      "         -5.6544e-01, -4.4657e-01, -8.2439e-01, -9.6341e-01,  5.9714e-01,\n",
      "          4.7455e-01, -1.3372e-01, -2.1858e-01, -2.7737e-01, -4.2491e-01,\n",
      "          2.1793e-02,  3.8048e-02, -8.2862e-01,  7.2883e-01, -1.2442e-01,\n",
      "          1.8588e-01, -1.2756e-01,  2.9686e-01, -6.5291e-01,  9.0465e-01,\n",
      "          3.6745e-01,  1.3379e-01,  4.1764e-02, -5.9463e-01,  5.1542e-01,\n",
      "         -5.6456e-01,  4.5725e-01, -2.4790e-02,  9.9972e-01, -1.7480e-01,\n",
      "         -4.9399e-01,  4.9845e-01,  3.8392e-01,  2.9808e-02,  3.7521e-02,\n",
      "         -4.0294e-01, -6.8956e-02,  7.8268e-01,  6.1394e-01, -2.3415e-01,\n",
      "         -4.9835e-02,  3.4101e-01, -4.7639e-01, -6.3462e-01,  5.8626e-01,\n",
      "          1.4089e-01, -1.2873e-01,  1.3418e-01, -6.7640e-02,  9.4701e-01,\n",
      "          9.5382e-02, -3.8935e-03, -2.1119e-01,  1.4159e-01, -8.9338e-02,\n",
      "         -1.6646e-01,  9.9863e-01,  2.1715e-01, -1.2610e-01, -9.7483e-01,\n",
      "          3.6701e-01, -7.3549e-01,  9.7840e-01,  6.4593e-01, -6.6286e-01,\n",
      "          3.0976e-01,  1.3858e-01, -2.3034e-02,  3.0813e-01, -3.7890e-02,\n",
      "         -1.5763e-01, -4.6937e-02, -5.8171e-02,  8.7599e-01, -1.8467e-01,\n",
      "         -9.2480e-01, -5.1535e-01,  1.3993e-01, -8.7685e-01,  7.5759e-01,\n",
      "         -3.2067e-01,  9.5537e-03, -1.3735e-01,  3.8716e-01,  3.0921e-01,\n",
      "         -2.1999e-01, -9.3041e-01, -8.1142e-03, -1.4479e-01,  9.1306e-01,\n",
      "         -2.1494e-03, -2.1355e-01, -8.2879e-01, -5.7012e-01, -1.4964e-01,\n",
      "          6.0185e-01, -8.4575e-01,  9.2995e-01, -9.1347e-01, -1.5538e-02,\n",
      "          9.9726e-01,  2.5287e-01, -6.5016e-01, -7.0641e-02, -1.2795e-01,\n",
      "          2.1220e-02,  2.0975e-01,  2.9746e-01, -8.8409e-01, -1.3898e-02,\n",
      "         -1.1187e-02,  2.7827e-02,  8.5043e-02,  2.7813e-01,  5.3502e-01,\n",
      "          1.2557e-01, -1.5363e-01, -2.8532e-01,  2.1232e-02,  1.6922e-01,\n",
      "          4.8245e-01, -9.9708e-02, -5.7214e-02, -6.1396e-02,  1.9992e-02,\n",
      "         -6.3414e-01, -8.5867e-02, -6.3883e-02, -8.8373e-01,  3.9564e-01,\n",
      "         -9.9960e-01, -4.8734e-01, -7.2115e-01, -1.3306e-02,  6.9440e-01,\n",
      "          1.6834e-01, -2.0344e-01, -5.3675e-01,  6.9538e-01,  8.6270e-01,\n",
      "          5.6520e-01, -1.5321e-03,  3.9462e-01, -4.9451e-01,  2.5764e-02,\n",
      "          5.9627e-02,  1.6766e-01,  4.2937e-01,  6.5393e-01,  3.9388e-02,\n",
      "          9.9971e-01, -7.9216e-02, -2.3026e-01, -7.8470e-01,  7.8037e-02,\n",
      "         -2.3839e-02,  9.9417e-01, -6.6308e-01, -9.0412e-01,  5.7247e-02,\n",
      "         -3.3679e-01, -6.8337e-01,  3.0714e-02, -1.0151e-01, -5.0762e-01,\n",
      "          1.4564e-01,  8.4607e-01,  5.9990e-01, -2.5888e-01,  4.8224e-02,\n",
      "         -1.5396e-01, -2.1891e-01, -1.1663e-01, -5.9266e-01,  9.6907e-01,\n",
      "          2.2509e-01,  7.3250e-01,  6.3838e-01,  1.4847e-01,  9.1249e-01,\n",
      "          1.2353e-01,  1.2676e-01, -5.9186e-02,  9.9796e-01,  1.1942e-01,\n",
      "         -8.8783e-01,  3.3056e-01, -9.4649e-01, -1.7194e-02, -8.7170e-01,\n",
      "          5.4431e-02, -9.2018e-02,  7.4990e-01, -1.3685e-01,  8.7731e-01,\n",
      "          5.8512e-01, -3.9967e-02,  3.5691e-01,  6.7755e-01,  1.3530e-01,\n",
      "         -8.2797e-01, -9.6292e-01, -9.6638e-01,  1.6982e-01, -2.4922e-01,\n",
      "          4.8534e-02,  1.2356e-01, -4.4928e-02,  1.6997e-01,  1.3991e-01,\n",
      "         -9.9812e-01,  8.5917e-01,  1.3116e-01, -6.7448e-01,  9.1429e-01,\n",
      "         -1.7376e-01,  1.8993e-01,  1.0379e-01, -9.6249e-01, -6.7406e-01,\n",
      "         -9.2020e-02, -1.7960e-01,  6.1456e-01,  3.8399e-01,  6.5780e-01,\n",
      "          7.9303e-02, -3.4926e-01, -1.6868e-01,  6.4368e-01, -3.1333e-01,\n",
      "         -9.7658e-01,  2.5060e-01,  5.2191e-01, -7.8517e-01,  9.0777e-01,\n",
      "         -6.4327e-01,  2.8006e-02,  7.8653e-01,  2.5740e-01,  7.1428e-01,\n",
      "          5.1591e-01,  2.6600e-01, -3.5239e-02,  4.0100e-01,  7.2236e-01,\n",
      "          8.5583e-01,  9.6624e-01,  5.4959e-01,  4.8584e-01,  5.7077e-01,\n",
      "          1.9605e-01,  5.9143e-01, -8.8107e-01, -5.9676e-02, -8.1290e-02,\n",
      "          2.9411e-01,  8.8920e-03, -1.0325e-01, -7.8792e-01,  5.5782e-01,\n",
      "         -4.4443e-02,  2.7493e-01, -1.9021e-01,  2.6037e-01, -2.5844e-01,\n",
      "         -4.7623e-02, -5.9908e-01, -1.7202e-01,  3.4450e-01,  2.2137e-02,\n",
      "          8.2464e-01,  7.9778e-02,  1.4314e-01, -3.2196e-01,  2.9868e-02,\n",
      "          7.1412e-01, -8.5140e-01,  7.7037e-01,  1.9861e-01,  7.5713e-01,\n",
      "         -2.1752e-01, -2.2381e-01,  7.5021e-01, -4.7710e-01, -1.6423e-01,\n",
      "         -5.4017e-02, -5.6105e-01,  5.7359e-01, -2.1983e-01, -2.6416e-01,\n",
      "         -2.1125e-01,  4.5557e-01,  1.0565e-01,  8.8416e-01,  5.5274e-01,\n",
      "          6.1209e-01, -1.4658e-01, -1.0410e-02,  2.2855e-01, -1.3907e-01,\n",
      "         -9.9835e-01,  1.8072e-01,  4.1899e-01, -5.0548e-01,  2.8743e-01,\n",
      "         -5.1701e-01,  3.2364e-01, -8.9282e-01, -1.4222e-02,  7.0023e-02,\n",
      "         -4.5465e-01, -3.0722e-01,  3.1304e-02,  1.7084e-01,  6.5287e-01,\n",
      "         -1.8043e-01,  7.8384e-01,  1.4807e-01,  6.8204e-01,  2.0559e-01,\n",
      "          1.8739e-01, -4.5317e-01,  6.9402e-01]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize a sentence\n",
    "input_ids = tokenizer.encode(\"Here is some text to encode\", return_tensors='pt')\n",
    "\n",
    "# Create a quantized version of the model\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(quantized_model(input_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the original model\n",
      "0\n",
      "Size of the quantized model\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Check the size of the original model\n",
    "print('Size of the original model')\n",
    "print(torch.cuda.memory_allocated())\n",
    "\n",
    "# Quantize the model\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# Check the size of the quantized model\n",
    "print('Size of the quantized model')\n",
    "print(torch.cuda.memory_allocated())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from sentence_transformers) (4.32.0.dev0)\n",
      "Requirement already satisfied: tqdm in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from sentence_transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from sentence_transformers) (1.1.3)\n",
      "Requirement already satisfied: scipy in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from sentence_transformers) (1.9.3)\n",
      "Requirement already satisfied: nltk in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from sentence_transformers) (3.8.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from sentence_transformers) (0.16.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2022.11.0)\n",
      "Requirement already satisfied: filelock in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n",
      "Requirement already satisfied: sympy in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from torch>=1.6.0->sentence_transformers) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from torch>=1.6.0->sentence_transformers) (2.11.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
      "Requirement already satisfied: click in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from nltk->sentence_transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from torchvision->sentence_transformers) (9.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ankitkothari/Library/Python/3.9/lib/python/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Building wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=17c723d7cfb319f0624437fdd6d6ff0adffaa6f88911c6ed1cc6446b67814431\n",
      "  Stored in directory: /Users/ankitkothari/Library/Caches/pip/wheels/4b/68/65/aba8be86302d9988b832f5e1f3417a87e4a868d396e4329f0a\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: sentencepiece, sentence_transformers\n",
      "Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.99\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5a39f9c97945339eb021943d3292a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a8e1d/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152ef5e717b542b1ad86d941ae188574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090033038867464c867ebd1fc2d859e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b20bca8e1d/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae26fff9f354a57bc2125744c13e539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0bca8e1d/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f98315a32494d9d9d7c25eeabfda011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6b43f5800d4d88874ab53d3608e51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e1d/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5d8b08fda747cf9fb4c0160cda8ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e450ead6fb4849b62ade0db76dd961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9d30e562c24279b9bcfe382622d7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ee625a843f4016af0c99311a8b9944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a8e1d/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5717e8a4a534dc5846cf218728b7250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3e4a82dc6548c0bbbf1226bcd20b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)8e1d/train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f629db3f8c4e0dbfd04bb1705d0285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b20bca8e1d/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3565aeaf1a40f081260c18ffcfbb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)bca8e1d/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104c8fa82df743cd9143eb6252813dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4fb387b47f4aac89958af815736218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f9fc41b87d40d99cc1a64de1e88058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b2a3cb20ee46d6aff19402f7f5f9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8393bc10640943f2a622c29770afdebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92907d5c0e1427284a3d52f3bd9f970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load SentenceTransformer model\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Convert the SentenceTransformer to a Huggingface model format\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "hf_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Ensure that the output hidden states are returned\n",
    "hf_model.config.output_hidden_states = True\n",
    "\n",
    "# Check if PyTorch supports quantization\n",
    "if not hasattr(torch.quantization, \"QuantStub\"):\n",
    "    raise SystemExit(\"PyTorch version does not support quantization!\")\n",
    "\n",
    "# Quantize the model\n",
    "# First, set the model to evaluation mode and fuse modules\n",
    "hf_model.eval()\n",
    "\n",
    "# Quantize the model\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    hf_model,  # the original model\n",
    "    {torch.nn.Linear},  # which layers to quantize\n",
    "    dtype=torch.qint8  # quantize to int8\n",
    ")\n",
    "\n",
    "def get_last_hidden_state(product_description, max_length=384):\n",
    "    \"\"\"Get the last hidden state for a product description using the quantized model.\"\"\"\n",
    "    inputs = tokenizer(product_description, return_tensors=\"pt\", truncation=True, max_length=max_length, padding='max_length')\n",
    "    with torch.no_grad():\n",
    "        outputs = quantized_model(**inputs)\n",
    "        last_hidden_state = outputs.hidden_states[-1]  # Get the last hidden state\n",
    "    return last_hidden_state\n",
    "\n",
    "# Test\n",
    "product_description = \"This is a sample product description for testing purposes.\"\n",
    "embedding = get_last_hidden_state(product_description)\n",
    "\n",
    "print(embedding.shape)  # Should be [1, 384, hidden_size], where hidden_size depends on the model's configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.5339e-02,  4.8094e-04, -3.2875e-03, -8.5614e-02, -3.1399e-02,\n",
       "         3.3346e-02,  2.4699e-01,  1.2367e-01, -2.8482e-01, -5.1928e-02,\n",
       "         1.3701e-01, -2.3313e-01,  1.0737e-01,  2.7213e-01,  1.6152e-01,\n",
       "        -1.2773e-01, -8.7884e-02,  5.4180e-02, -3.2831e-01, -2.2150e-02,\n",
       "        -7.5036e-02, -1.6091e-02,  8.7497e-02,  5.8058e-02,  1.5023e-01,\n",
       "         8.3891e-02, -5.0910e-02, -6.2932e-02, -1.5361e-02, -1.3554e-01,\n",
       "        -7.0830e-02,  7.7708e-02, -1.0217e-02, -2.7404e-01,  5.9497e-06,\n",
       "        -4.3983e-02,  9.1703e-02, -1.6065e-02, -1.0417e-01,  4.4746e-02,\n",
       "         1.5664e-01,  1.2910e-02,  5.6268e-02,  1.3138e-01, -2.1772e-02,\n",
       "        -7.2253e-02, -1.3816e-02,  4.2662e-02, -1.6519e-01,  3.4917e-02,\n",
       "         6.2888e-02, -9.3230e-02, -8.3270e-02, -6.3368e-02,  1.2814e-01,\n",
       "         6.9656e-02, -1.3702e-01, -9.6704e-02,  1.2918e-01, -8.3936e-02,\n",
       "         3.2028e-03, -1.4644e-01, -4.2841e-02, -4.6413e-02,  7.3504e-02,\n",
       "         9.4557e-02,  1.2160e-01,  1.3731e-02, -8.3805e-02,  6.9993e-02,\n",
       "         8.4080e-02,  1.1692e-01, -8.6670e-02,  1.2450e-01, -2.9435e-02,\n",
       "         1.7987e-01, -3.3373e-02,  8.1792e-02, -5.3552e-02, -1.1068e-01,\n",
       "        -7.3365e-02,  3.1054e-02,  4.0539e-03, -4.5026e-02, -1.0123e-02,\n",
       "         1.2707e-01, -6.4070e-02,  7.5677e-02,  2.8484e-02, -9.6238e-02,\n",
       "         8.5160e-02, -1.9730e-02, -1.1374e-01,  4.8305e-02, -2.9973e-02,\n",
       "        -2.2943e-02,  3.4503e-02, -2.0322e-01,  5.9717e-02,  2.9734e-02,\n",
       "        -2.7685e-02,  4.4709e-02,  1.9261e-01, -1.5962e-03, -7.2979e-02,\n",
       "         1.5863e-01,  1.8841e-01, -3.1958e-02, -2.6216e-01,  1.6161e-01,\n",
       "         7.4948e-02,  2.0181e-02,  2.6300e-02,  2.6021e-02, -7.9616e-03,\n",
       "        -1.1445e-02,  4.7215e-02,  1.3557e-02, -7.3748e-02,  4.0949e-02,\n",
       "         1.8280e-02,  9.9417e-02, -2.4334e-01,  7.3898e-02, -2.7667e-02,\n",
       "        -7.4047e-02, -8.0443e-03, -1.8120e-01,  2.0736e-01,  1.2190e-01,\n",
       "        -1.1319e-01,  5.0907e-02, -8.0770e-02, -4.9519e-02,  7.2212e-02,\n",
       "         1.3984e-01, -1.4124e-02, -1.1554e-01,  1.1742e-01, -7.2312e-02,\n",
       "         1.0986e-01, -5.5755e-03, -1.2329e-02,  1.1247e-01,  1.0072e-02,\n",
       "        -7.2864e-02,  2.6213e-02,  1.5605e-01, -8.8318e-02, -4.3791e-02,\n",
       "        -5.3883e-03, -5.2314e-02, -1.2611e-01,  2.6322e-02, -1.3485e-01,\n",
       "         5.3792e-02,  1.6287e-01, -2.5790e-01, -1.5136e-01,  8.8947e-02,\n",
       "        -2.5881e-02, -1.3891e-02, -4.6860e-02,  4.1587e-02, -1.6543e-01,\n",
       "        -2.7154e-02, -2.1173e-01, -1.8539e-02, -2.2056e-01, -1.6646e-02,\n",
       "        -8.5651e-02, -9.1571e-02, -1.7881e-01,  1.8279e-01,  6.1747e-02,\n",
       "         2.7959e-01, -7.3306e-02, -1.4152e-01, -3.2270e-02,  1.5909e-01,\n",
       "        -2.8864e-02, -2.4964e-01,  2.5874e-02,  1.9018e-02,  7.5370e-02,\n",
       "         4.3617e-02,  2.3365e-03,  1.0686e-01, -1.5146e-01,  1.3978e-03,\n",
       "         3.7185e-02, -2.2664e-02,  1.2032e-01,  1.2426e-01, -8.0963e-02,\n",
       "         2.6110e-03, -9.0807e-02,  4.1527e-02,  1.1474e-01, -4.8443e-02,\n",
       "         1.1214e-02, -9.5217e-02,  3.2971e-01,  2.9124e-02, -4.3103e-02,\n",
       "         5.6045e-02,  5.7831e-03, -1.3343e-01, -1.2440e-01,  2.4381e-01,\n",
       "        -8.0783e-02,  1.6445e-02, -5.7787e-02,  3.4390e-02, -1.0986e-01,\n",
       "        -1.0223e-01,  1.0392e-01,  4.1536e-02, -1.0098e-01, -6.5858e-02,\n",
       "        -7.6078e-02,  5.2317e-02, -5.0658e-02,  6.8953e-02,  1.3968e-01,\n",
       "         2.9328e-02,  1.9426e-01, -1.4084e-02, -4.0145e-02,  4.6271e-02,\n",
       "        -1.4711e-02, -9.5514e-02,  1.0078e-01,  8.1040e-02, -6.1714e-02,\n",
       "         1.0376e-01,  2.6101e-01, -2.5225e-01, -1.2408e-01, -1.6037e-01,\n",
       "        -6.4277e-02,  2.6830e-02,  1.1220e-02,  3.9214e-02,  4.1409e-02,\n",
       "         4.3376e-02, -1.5355e-01,  2.0191e-03,  7.6151e-02, -2.3339e-01,\n",
       "         5.6815e-03, -3.5424e-02,  2.6408e-02, -5.8952e-02,  9.6509e-02,\n",
       "        -1.4103e-02, -1.0326e-01, -7.5201e-02,  9.7520e-02,  2.6070e-02,\n",
       "         3.5380e-02, -9.1812e-02,  3.0110e-03, -5.6187e-02,  2.0408e-01,\n",
       "        -2.2521e-02,  3.2622e-02,  4.4871e-02,  9.9381e-02,  4.9977e-03,\n",
       "         2.1883e-01, -5.4295e-03, -8.6304e-02,  5.6363e-02,  1.4434e-01,\n",
       "        -2.0925e-01, -1.1862e-01,  3.0898e-03, -7.7726e-02, -1.9365e-02,\n",
       "         9.7916e-02,  5.2448e-02,  2.2825e-01,  8.9744e-02,  7.2941e-02,\n",
       "         1.8106e-01, -3.4758e-03,  8.8904e-02, -1.6027e-01,  6.9615e-02,\n",
       "         4.5614e-02, -2.0825e-01,  7.6572e-02,  1.5172e-01,  1.0864e-02,\n",
       "         7.1877e-02,  9.8707e-02,  6.1158e-02,  4.6179e-02,  1.0613e-01,\n",
       "         6.1918e-02,  1.7426e-01, -1.1737e-01, -4.5122e-02, -7.7133e-02,\n",
       "         1.8144e-01, -8.2870e-03, -1.3709e-01,  2.1475e-02, -6.5785e-02,\n",
       "        -6.4073e-02, -3.4930e-02, -5.9606e-02,  1.7750e-01, -9.9698e-02,\n",
       "         1.1974e-01,  1.6203e-02, -1.5266e-01, -7.4330e-02, -2.9171e-02,\n",
       "        -9.7910e-02,  1.0474e-01,  1.0112e-01,  3.3441e-02,  3.3171e-02,\n",
       "        -4.6881e-02, -1.6606e-01,  1.1404e-01, -1.2307e-02, -1.1229e-01,\n",
       "         9.5377e-02,  4.7532e-02, -4.4798e-02,  4.1207e-02, -1.1320e-03,\n",
       "         3.2002e-04, -5.9373e-02,  6.1514e-02, -3.7589e-02,  5.7107e-03,\n",
       "        -8.3666e-02,  7.8297e-02,  8.8074e-02, -1.5289e-01,  3.3233e-01,\n",
       "        -2.5621e-02, -6.0525e-02,  1.2304e-03, -1.1500e-01,  1.3673e-01,\n",
       "         8.5572e-02,  5.0853e-02, -1.0683e-01, -1.2283e-01,  1.1977e-02,\n",
       "        -6.1442e-02, -1.3637e-02,  6.2745e-02, -4.5940e-02, -2.7452e-01,\n",
       "        -1.1361e-01, -1.0446e-02,  1.1580e-01,  2.3512e-01, -1.2066e-01,\n",
       "        -1.4912e-01,  8.3860e-02,  2.2824e-02, -4.1630e-02,  4.9597e-02,\n",
       "        -1.2666e-01,  3.4874e-02,  7.6843e-02,  1.2594e-01, -1.5737e-02,\n",
       "        -5.2530e-02,  9.4697e-02,  2.9899e-01, -1.3244e-01, -1.0692e-01,\n",
       "         9.9132e-02,  8.3601e-04,  9.6379e-03, -9.4878e-03,  5.0211e-02,\n",
       "         1.6838e-01,  4.4600e-02, -5.7166e-02, -8.4948e-02, -8.5374e-02,\n",
       "         6.8216e-03, -1.5043e-01, -1.2686e-01,  3.5623e-02, -7.9285e-02,\n",
       "         3.3617e-02,  2.7207e-01, -3.5038e-02, -2.1212e-02,  8.0442e-02,\n",
       "         4.5813e-02,  4.2581e-03, -2.1451e-01,  1.5168e-01,  1.0165e-01,\n",
       "         3.1889e-03,  9.3434e-02, -1.1581e-02, -1.1118e-01,  7.0922e-02,\n",
       "        -7.1038e-02,  7.6226e-02, -2.7393e-02,  4.3873e-02,  2.1148e-01,\n",
       "         3.4201e-02,  1.0434e-01,  3.9402e-02,  4.5487e-02, -3.0330e-02,\n",
       "         5.7984e-02, -4.8030e-02, -1.2405e-03, -6.9550e-02, -3.6521e-02,\n",
       "        -6.5997e-02,  7.9247e-02, -2.3503e-04,  6.2040e-02, -9.1065e-02,\n",
       "        -2.4674e-01,  5.5469e-02, -4.1327e-02, -1.2496e-02, -1.1594e-01,\n",
       "        -5.4222e-02, -3.3122e-02, -1.4438e-01,  5.0609e-02, -1.1456e-01,\n",
       "        -8.4767e-02, -1.1187e-01,  2.5043e-01,  1.8451e-01,  1.1256e-01,\n",
       "         1.3870e-01, -2.3424e-01,  1.2533e-01,  1.4382e-01,  1.2432e-01,\n",
       "         6.1906e-02,  1.6083e-01,  3.3139e-02, -2.4595e-01,  4.7376e-02,\n",
       "        -7.1965e-02, -1.9077e-01, -7.5961e-03, -2.0290e-01,  5.6208e-03,\n",
       "        -8.4845e-02, -1.2059e-02, -1.2620e-01,  1.0880e-01, -1.1625e-01,\n",
       "         7.3204e-02,  1.7065e-03,  5.0744e-02,  6.1943e-02, -1.9138e-01,\n",
       "        -6.2044e-02, -5.6249e-02, -2.2925e-02,  1.0937e-04,  6.8912e-03,\n",
       "         4.8004e-02, -9.2832e-02,  1.1538e-01, -1.4999e-01,  8.4429e-02,\n",
       "         1.0922e-02, -2.7601e-02, -1.8700e-02, -5.0012e-03,  4.8644e-02,\n",
       "        -2.3320e-02,  7.1654e-02, -3.8530e-02,  1.1811e-02, -1.3562e-01,\n",
       "        -3.1142e-02, -1.5926e-01, -2.0613e-02,  1.6750e-01,  1.3090e-02,\n",
       "         5.1083e-02,  6.1875e-03,  1.7201e-03, -1.7322e-01, -2.3572e-01,\n",
       "        -6.8446e-05,  9.6076e-02, -1.0810e-01, -1.3189e-01, -3.8923e-02,\n",
       "         3.1959e-02,  1.7415e-02,  5.5865e-02,  1.4076e-02, -3.7687e-02,\n",
       "        -3.5398e-02,  1.9614e-02,  5.5845e-02, -1.8355e-01, -7.6770e-02,\n",
       "        -2.1795e-02, -2.4084e-01, -8.1439e-02,  1.1945e-01,  9.6410e-02,\n",
       "         5.4544e-02, -5.9494e-02,  1.1182e-02, -1.1184e-01, -1.1144e-01,\n",
       "        -2.9481e-03,  2.3752e-02, -1.4447e-02, -2.0760e-01,  1.3860e-01,\n",
       "         1.8001e-01, -1.4450e-01,  1.5619e-01,  7.3623e-02, -1.4216e-01,\n",
       "         2.2876e-01,  7.5914e-02, -2.7348e-02, -9.3271e-02, -1.6270e-02,\n",
       "        -4.9901e-02, -1.5106e-02,  1.2127e-01,  6.1369e-02,  1.9990e-01,\n",
       "         1.3290e-02,  1.4264e-01, -4.7067e-02, -8.1199e-02, -1.1325e-01,\n",
       "         9.0324e-02, -7.8387e-03,  2.7871e-02, -8.2959e-03, -3.6182e-02,\n",
       "        -2.6997e-32, -1.8892e-02, -1.6318e-01, -6.0037e-02,  1.0522e-01,\n",
       "        -8.6413e-02, -2.7326e-01, -1.2745e-01, -7.9398e-02,  1.4471e-02,\n",
       "         7.0802e-03,  1.3595e-02, -2.9045e-02,  1.4856e-01,  2.6389e-01,\n",
       "         8.3819e-03, -3.1275e-02,  8.7485e-02, -6.1104e-02,  1.2115e-03,\n",
       "        -3.9417e-02, -1.0764e-01,  7.9458e-02,  1.3820e-02,  1.0461e-01,\n",
       "        -5.2381e-02, -4.8931e-02, -7.5834e-02, -4.9646e-02, -1.1356e-01,\n",
       "        -1.3799e-01,  6.0045e-02, -1.3609e-02,  4.1292e-02,  9.9448e-02,\n",
       "        -8.6357e-02, -1.3503e-02,  6.7298e-03, -5.2154e-02, -2.7165e-02,\n",
       "        -8.5091e-02, -1.9807e-01,  1.4274e-01,  1.7042e-02, -4.9777e-02,\n",
       "        -9.6766e-02,  1.3732e-02,  6.0079e-02, -1.0402e-01, -6.6677e-02,\n",
       "        -2.2520e-01, -1.0981e-01, -2.8595e-02, -4.8471e-02,  1.4972e-01,\n",
       "         1.4712e-01,  1.6758e-01,  1.1206e-01, -3.5283e-01,  1.7389e-01,\n",
       "        -8.2187e-02,  2.0778e-01, -2.2684e-02, -5.4002e-02,  1.4905e-01,\n",
       "         5.0987e-02,  2.9745e-02, -9.4846e-02,  4.3120e-02,  3.6295e-01,\n",
       "        -2.3661e-01,  3.0718e-02,  2.7742e-02,  7.2806e-03,  1.3103e-01,\n",
       "        -4.6062e-02, -6.4787e-02,  1.2010e-02,  1.8837e-01,  1.3634e-01,\n",
       "        -1.8531e-01,  5.6021e-02, -5.6619e-02,  6.7984e-02, -1.0277e-01,\n",
       "        -1.4316e-01,  1.2335e-02,  2.1751e-02,  5.0506e-02,  7.1288e-03,\n",
       "         1.1499e-02, -1.5629e-01,  1.5142e-01, -9.4968e-02, -5.4383e-02,\n",
       "         5.2665e-03, -1.0393e-01,  4.4399e-03,  9.6392e-03, -3.7464e-02,\n",
       "        -1.4530e-01, -1.7235e-02, -9.7106e-02, -4.3471e-02,  4.0034e-02,\n",
       "        -1.9190e-02, -9.0200e-02, -2.0698e-02,  8.5749e-02, -1.1543e-01,\n",
       "         1.7401e-01,  6.7997e-02,  1.5575e-01,  6.1661e-02, -1.4973e-01,\n",
       "        -2.2838e-02,  2.8946e-02,  9.4756e-02, -7.8189e-02,  1.4689e-01,\n",
       "        -1.3398e-01,  3.6653e-02, -2.1477e-02,  1.1625e-01,  7.2933e-03,\n",
       "         2.3938e-02,  1.2796e-01,  3.7229e-02,  2.7832e-02,  2.7371e-01,\n",
       "         6.3296e-02,  3.5092e-03,  4.0186e-02,  7.7076e-07,  2.6667e-02,\n",
       "        -4.6519e-02, -7.9494e-02,  1.2315e-02,  5.8170e-02,  1.4878e-01,\n",
       "         7.3705e-02,  1.4808e-01, -5.4038e-02,  1.7860e-02,  1.6603e-02,\n",
       "        -1.6305e-01,  7.6800e-02,  1.2344e-01, -3.6161e-02, -3.3288e-02,\n",
       "         1.3982e-02, -3.0918e-02, -8.2273e-02,  1.8799e-02,  1.9979e-01,\n",
       "         5.5029e-02,  2.9059e-03, -1.6782e-02,  2.6554e-02, -6.4045e-02,\n",
       "         4.9924e-02, -7.5321e-02,  1.3650e-02,  4.8006e-02, -3.3480e-02,\n",
       "         4.4004e-02, -9.1368e-02,  2.1887e-01,  4.9843e-02, -2.5510e-02,\n",
       "        -2.7637e-02,  9.5568e-02,  4.5802e-02, -9.3436e-03,  2.6184e-02,\n",
       "        -2.7379e-01,  2.3679e-02,  4.3659e-02, -3.4872e-02, -1.5710e-01,\n",
       "         1.5374e-02, -7.5341e-02, -7.7234e-02,  8.9879e-02, -2.5365e-02,\n",
       "         5.2458e-02,  1.2250e-01,  4.7398e-02, -9.1869e-03, -2.2244e-01,\n",
       "         1.1439e-02,  1.8599e-02, -2.6017e-02,  1.0839e-01, -1.3434e-01,\n",
       "        -6.9564e-03,  6.5071e-02,  2.1315e-01,  4.6545e-02, -1.9929e-01,\n",
       "        -1.0434e-01,  1.9148e-34,  2.3511e-02,  1.3047e-02,  3.1149e-02,\n",
       "         5.9443e-02, -2.2284e-02, -7.8412e-02,  1.6315e-01, -1.3503e-02,\n",
       "        -4.9457e-02, -1.0955e-01, -1.2135e-01])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
